# generate_embeddings.py
import json
import numpy as np
import google.generativeai as genai
import os
import re

# API í‚¤
try:
    import toml
    secrets = toml.load(".streamlit/secrets.toml")
    API_KEY = secrets["GOOGLE_API_KEY"]
except:
    API_KEY = input("Google API Key: ")

genai.configure(api_key=API_KEY)

EMBEDDING_MODEL = "models/text-embedding-004"

def embed_text(text):
    clean_text = text.replace("\n", " ").strip()
    if not clean_text:
        return None
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=clean_text,
            task_type="retrieval_document",
        )
        return result["embedding"]
    except Exception as e:
        print(f"[Error] {e}")
        return None

print("=" * 60)
print("ì„ë² ë”© ìƒì„± ì‹œì‘")
print("=" * 60)

# 1. ë²•ë ¹ ì„ë² ë”©
print("\n[1/2] ë²•ë ¹ ì„ë² ë”©...")
statute_items = []
statute_embeddings = []

if os.path.exists("statutes_data.txt"):
    with open("statutes_data.txt", "r", encoding="utf-8") as f:
        content = f.read()
    
    parts = re.split(r"\s*---END OF STATUTE---\s*", content)
    parts = [p.strip() for p in parts if p.strip()]
    
    print(f"   ì´ {len(parts)}ê°œ ë²•ë ¹ ë°œê²¬")
    
    for i, p in enumerate(parts):
        if i % 5 == 0:
            print(f"   ì§„í–‰: {i+1}/{len(parts)}")
        
        emb = embed_text(p)
        if emb:
            statute_items.append({"rag_index": p, "raw_text": p})
            statute_embeddings.append(emb)
    
    np.save("statutes_embeddings.npy", np.array(statute_embeddings))
    with open("statutes_items.json", "w", encoding="utf-8") as f:
        json.dump(statute_items, f, ensure_ascii=False, indent=2)
    
    print(f"   âœ… ì™„ë£Œ: {len(statute_items)}ê°œ")
else:
    print("   âŒ statutes_data.txt ì—†ìŒ!")

# 2. íŒë¡€ ì„ë² ë”© (ì„ì‹œ ìƒì„±)
print("\n[2/2] íŒë¡€ ìƒì„± ë° ì„ë² ë”©...")

precedents = [
    {
        "id": "2023ë„12345",
        "title": "ë§ˆì•½ë¥˜ê´€ë¦¬ë²•ìœ„ë°˜(í–¥ì •)-ë§¤ë§¤",
        "court": "ëŒ€ë²•ì›",
        "date": "2023-05-15",
        "summary": "í•„ë¡œí° íŒë§¤ ê³µë²” ì‹¤í˜• 3ë…„",
        "rag_index": "í”¼ê³ ì¸ì´ ê³µë™ìœ¼ë¡œ í•„ë¡œí° 50gì„ íŒë§¤í•œ ì‚¬ì‹¤ì´ ì¸ì •ë¨. ì¡°ì§ì  ìœ í†µë§ì— ê´€ì—¬í•˜ì˜€ê³  ì˜ë¦¬ ëª©ì ì´ ëª…ë°±í•˜ì—¬ ì§•ì—­ 3ë…„ ì‹¤í˜• ì„ ê³ ",
        "full_text": "í”¼ê³ ì¸ë“¤ì€ 2023ë…„ 3ì›”ë¶€í„° 5ì›”ê¹Œì§€ ê³µë™ìœ¼ë¡œ í•„ë¡œí° 50gì„ íŒë§¤í•˜ì˜€ë‹¤. ì¡°ì§ì  ìœ í†µë§ì— ê´€ì—¬í•˜ì˜€ê³  ì˜ë¦¬ ëª©ì ì´ ëª…ë°±í•˜ë‹¤. ì§•ì—­ 3ë…„ì„ ì„ ê³ í•œë‹¤.",
        "url": "https://example.com/case1"
    },
    {
        "id": "2022ë„67890",
        "title": "ë§ˆì•½ë¥˜ê´€ë¦¬ë²•ìœ„ë°˜(í–¥ì •)-ë§¤ë§¤",
        "court": "ì„œìš¸ì¤‘ì•™ì§€ë²•",
        "date": "2022-11-20",
        "summary": "í•„ë¡œí° íŒë§¤ ì´ˆë²” ì§‘í–‰ìœ ì˜ˆ",
        "rag_index": "í”¼ê³ ì¸ì´ í•„ë¡œí° 10gì„ íŒë§¤í•˜ì˜€ìœ¼ë‚˜ ì´ˆë²”ì´ê³  ìë°±í•˜ë©° ê¹Šì´ ë°˜ì„±í•˜ì—¬ ì§•ì—­ 2ë…„ ì§‘í–‰ìœ ì˜ˆ 3ë…„ ì„ ê³ ",
        "full_text": "í”¼ê³ ì¸ì€ í•„ë¡œí° 10gì„ íŒë§¤í•˜ì˜€ë‹¤. ì´ˆë²”ì´ê³  ìë°±í•˜ë©° ë°˜ì„±í•˜ëŠ” íƒœë„ë¥¼ ë³´ì˜€ë‹¤. ì§•ì—­ 2ë…„ ì§‘í–‰ìœ ì˜ˆ 3ë…„ì„ ì„ ê³ í•œë‹¤.",
        "url": "https://example.com/case2"
    },
    {
        "id": "2023ë„11111",
        "title": "ë§ˆì•½ë¥˜ê´€ë¦¬ë²•ìœ„ë°˜(í–¥ì •)-íˆ¬ì•½/ì†Œì§€",
        "court": "ìˆ˜ì›ì§€ë²•",
        "date": "2023-08-10",
        "summary": "í•„ë¡œí° íˆ¬ì•½ ë° ì†Œì§€ ì‹¤í˜• 1ë…„ 6ì›”",
        "rag_index": "í”¼ê³ ì¸ì´ í•„ë¡œí€ì„ íˆ¬ì•½í•˜ê³  5gì„ ì†Œì§€í•œ ì‚¬ì‹¤ì´ ì¸ì •ë¨. ë™ì¢… ì „ê³¼ 1íšŒ ìˆì–´ ì§•ì—­ 1ë…„ 6ì›” ì‹¤í˜• ì„ ê³ ",
        "full_text": "í”¼ê³ ì¸ì€ í•„ë¡œí°ì„ íˆ¬ì•½í•˜ê³  5gì„ ì†Œì§€í•˜ì˜€ë‹¤. ë™ì¢… ì „ê³¼ê°€ ìˆì–´ ì§•ì—­ 1ë…„ 6ì›”ì„ ì„ ê³ í•œë‹¤.",
        "url": "https://example.com/case3"
    },
    {
        "id": "2023ë„22222",
        "title": "ë§ˆì•½ë¥˜ê´€ë¦¬ë²•ìœ„ë°˜(í–¥ì •)-ë§¤ë§¤/ì•Œì„ ",
        "court": "ëŒ€ë²•ì›",
        "date": "2023-09-25",
        "summary": "ë§ˆì•½ ì•Œì„  ë° íŒë§¤ ì‹¤í˜• 4ë…„",
        "rag_index": "í”¼ê³ ì¸ì´ ë§ˆì•½ ê±°ë˜ë¥¼ ì•Œì„ í•˜ê³  ì§ì ‘ íŒë§¤ë„ ë³‘í–‰í•œ ì‚¬ì‹¤ì´ ì¸ì •ë¨. ì¡°ì§ì  ë²”í–‰ìœ¼ë¡œ ì§•ì—­ 4ë…„ ì‹¤í˜• ì„ ê³ ",
        "full_text": "í”¼ê³ ì¸ì€ ë§ˆì•½ ê±°ë˜ë¥¼ ì•Œì„ í•˜ê³  ì§ì ‘ íŒë§¤ë„ í•˜ì˜€ë‹¤. ì¡°ì§ì  ë²”í–‰ìœ¼ë¡œ ì§•ì—­ 4ë…„ì„ ì„ ê³ í•œë‹¤.",
        "url": "https://example.com/case4"
    },
    {
        "id": "2022ë„33333",
        "title": "ë§ˆì•½ë¥˜ê´€ë¦¬ë²•ìœ„ë°˜(í–¥ì •)-ë§¤ë§¤",
        "court": "ë¶€ì‚°ì§€ë²•",
        "date": "2022-12-15",
        "summary": "í•„ë¡œí° ëŒ€ëŸ‰ íŒë§¤ ì‹¤í˜• 5ë…„",
        "rag_index": "í”¼ê³ ì¸ì´ í•„ë¡œí° 200gì„ íŒë§¤í•˜ì—¬ ëŒ€ê·œëª¨ ìœ í†µì— ê´€ì—¬í•œ ì‚¬ì‹¤ì´ ì¸ì •ë¨. ì§•ì—­ 5ë…„ ì‹¤í˜• ì„ ê³ ",
        "full_text": "í”¼ê³ ì¸ì€ í•„ë¡œí° 200gì„ íŒë§¤í•˜ì˜€ë‹¤. ëŒ€ê·œëª¨ ìœ í†µì— ê´€ì—¬í•˜ì—¬ ì§•ì—­ 5ë…„ì„ ì„ ê³ í•œë‹¤.",
        "url": "https://example.com/case5"
    }
]

# JSONL ì €ì¥
with open("precedents_data.jsonl", "w", encoding="utf-8") as f:
    for p in precedents:
        f.write(json.dumps(p, ensure_ascii=False) + "\n")

print(f"   íŒë¡€ {len(precedents)}ê°œ ìƒì„±")

# ì„ë² ë”©
precedent_items = []
precedent_embeddings = []

for i, p in enumerate(precedents):
    print(f"   ì„ë² ë”©: {i+1}/{len(precedents)}")
    emb = embed_text(p["rag_index"])
    if emb:
        precedent_items.append(p)
        precedent_embeddings.append(emb)

np.save("precedents_embeddings.npy", np.array(precedent_embeddings))
with open("precedents_items.json", "w", encoding="utf-8") as f:
    json.dump(precedent_items, f, ensure_ascii=False, indent=2)

print(f"   âœ… ì™„ë£Œ: {len(precedent_items)}ê°œ")

print("\n" + "=" * 60)
print("ğŸ‰ ì™„ë£Œ!")
print("=" * 60)
