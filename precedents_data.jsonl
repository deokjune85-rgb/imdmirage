import requests
import json
import math
import xml.etree.ElementTree as ET
import time

# ===== 설정값 =====
OC = "deokjune"               # 네 OC ID
QUERY = "음주운전"             # 검색 키워드
TARGET = "prec"
TYPE = "XML"
BASE_URL = "http://www.law.go.kr/DRF"
OUTPUT_FILE = "precedents_data.jsonl"  # RAG에서 쓰던 파일명 그대로

# ===== 공통 유틸 =====
def safe_text(node):
    if node is None:
        return ""
    # 자식 포함 전체 텍스트
    return "".join(node.itertext()).strip()

def get_child_text(parent, tag):
    if parent is None:
        return ""
    node = parent.find(tag)
    return safe_text(node)

def fetch_search_page(page=1):
    params = {
        "OC": OC,
        "target": TARGET,
        "type": TYPE,
        "query": QUERY,
        "page": page,
        # display 안 먹으면 무시되더라도 상관 없음
        "display": 100,
    }
    resp = requests.get(f"{BASE_URL}/lawSearch.do", params=params, timeout=10)
    resp.raise_for_status()
    resp.encoding = "utf-8"
    return resp.text

def fetch_detail_xml(prec_id):
    params = {
        "OC": OC,
        "target": TARGET,
        "type": TYPE,
        "ID": prec_id,
    }
    resp = requests.get(f"{BASE_URL}/lawService.do", params=params, timeout=10)
    resp.raise_for_status()
    resp.encoding = "utf-8"
    return resp.text

# ===== 메인 로직 =====
def main():
    # 1페이지 먼저 호출해서 totalCnt / 페이지 수 계산
    first_xml = fetch_search_page(page=1)
    root = ET.fromstring(first_xml)

    total_cnt_text = root.findtext("totalCnt", "0")
    try:
        total_cnt = int(total_cnt_text)
    except ValueError:
        total_cnt = 0

    first_precs = root.findall("prec")
    per_page = len(first_precs) if len(first_precs) > 0 else 20
    total_pages = math.ceil(total_cnt / per_page) if per_page > 0 else 1

    print(f"[INFO] totalCnt={total_cnt}, per_page={per_page}, pages={total_pages}")

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        # 첫 페이지 처리
        pages_roots = [(1, root)]

        # 나머지 페이지들 가져오기
        for p in range(2, total_pages + 1):
            xml_text = fetch_search_page(page=p)
            r = ET.fromstring(xml_text)
            pages_roots.append((p, r))
            time.sleep(0.2)  # 너무 폭격하지 않도록 살짝 쉼

        # 각 페이지 순회
        for page_num, page_root in pages_roots:
            prec_list = page_root.findall("prec")
            print(f"[INFO] page {page_num}: {len(prec_list)} precedents")

            for prec in prec_list:
                prec_id = get_child_text(prec, "판례일련번호")
                case_name = get_child_text(prec, "사건명")
                case_number = get_child_text(prec, "사건번호")
                decision_date = get_child_text(prec, "선고일자")
                court_name = get_child_text(prec, "법원명")
                case_type = get_child_text(prec, "사건종류명")
                judgment_type = get_child_text(prec, "판결유형")
                decision_kind = get_child_text(prec, "선고")
                data_source = get_child_text(prec, "데이터출처명")

                # 상세 XML 호출
                detail_xml = fetch_detail_xml(prec_id)
                droot = ET.fromstring(detail_xml)

                # 주요 본문 필드 모아서 content 하나로 합치기
                parts = []
                for tag in ["판시사항", "판결요지", "참조조문", "참조판례", "판례내용"]:
                    txt = get_child_text(droot, tag)
                    if txt:
                        parts.append(f"[{tag}]\n{txt}")

                full_content = "\n\n".join(parts).strip()

                # law.go.kr PC용 대략적인 원문 URL (precSeq=판례일련번호)
                source_url = f"https://www.law.go.kr/precInfoP.do?precSeq={prec_id}"

                record = {
                    "id": f"prec_{prec_id}",
                    "keyword": QUERY,
                    "title": case_name,
                    "case_number": case_number,
                    "decision_date": decision_date,
                    "court_name": court_name,
                    "case_type": case_type,
                    "judgment_type": judgment_type,
                    "decision_kind": decision_kind,
                    "data_source": data_source,
                    "source_url": source_url,
                    "content": full_content,
                }

                f.write(json.dumps(record, ensure_ascii=False) + "\n")
                print(f"[OK] prec_id={prec_id}")

                time.sleep(0.1)  # 호출 간 살짝 딜레이

    print(f"[DONE] Saved to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
