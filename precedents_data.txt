import requests
import time
import math
import xml.etree.ElementTree as ET

OC = "deokjune"                  # 네 OC
QUERY = "음주운전"               # 검색 키워드
TARGET = "prec"
TYPE = "XML"
BASE_URL = "http://www.law.go.kr/DRF"
OUTPUT_TXT = "precedents_data.txt"


def safe_text(node):
    if node is None:
        return ""
    return "".join(node.itertext()).strip()


def get_child_text(parent, tag):
    if parent is None:
        return ""
    node = parent.find(tag)
    return safe_text(node)


def fetch_search_page(page=1):
    params = {
        "OC": OC,
        "target": TARGET,
        "type": TYPE,
        "query": QUERY,
        "page": page,
        "display": 100,
    }
    resp = requests.get(f"{BASE_URL}/lawSearch.do", params=params, timeout=10)
    resp.raise_for_status()
    resp.encoding = "utf-8"
    return resp.text


def fetch_detail_xml(prec_id):
    params = {
        "OC": OC,
        "target": TARGET,
        "type": TYPE,
        "ID": prec_id,
    }
    resp = requests.get(f"{BASE_URL}/lawService.do", params=params, timeout=10)
    resp.raise_for_status()
    resp.encoding = "utf-8"
    return resp.text


def main():
    first_xml = fetch_search_page(page=1)
    root = ET.fromstring(first_xml)

    total_cnt_text = root.findtext("totalCnt", "0")
    try:
        total_cnt = int(total_cnt_text)
    except ValueError:
        total_cnt = 0

    first_precs = root.findall("prec")
    per_page = len(first_precs) if len(first_precs) > 0 else 20
    total_pages = math.ceil(total_cnt / per_page) if per_page > 0 else 1

    print(f"[INFO] totalCnt={total_cnt}, per_page={per_page}, pages={total_pages}")

    pages_roots = [(1, root)]
    for p in range(2, total_pages + 1):
        xml_text = fetch_search_page(page=p)
        r = ET.fromstring(xml_text)
        pages_roots.append((p, r))
        time.sleep(0.2)

    with open(OUTPUT_TXT, "w", encoding="utf-8") as f:
        for page_num, page_root in pages_roots:
            prec_list = page_root.findall("prec")
            print(f"[INFO] page {page_num}: {len(prec_list)} precedents")

            for prec in prec_list:
                prec_id = get_child_text(prec, "판례일련번호")
                case_name = get_child_text(prec, "사건명")
                case_number = get_child_text(prec, "사건번호")
                decision_date = get_child_text(prec, "선고일자")
                court_name = get_child_text(prec, "법원명")
                case_type = get_child_text(prec, "사건종류명")
                judgment_type = get_child_text(prec, "판결유형")

                detail_xml = fetch_detail_xml(prec_id)
                droot = ET.fromstring(detail_xml)

                parts = []
                for tag in ["판시사항", "판결요지", "참조조문", "참조판례", "판례내용"]:
                    txt = get_child_text(droot, tag)
                    if txt:
                        parts.append(f"[{tag}]\n{txt}")

                full_content = "\n\n".join(parts).strip()

                block = (
                    "==== PRECEDENT START ====\n"
                    f"판례일련번호: {prec_id}\n"
                    f"사건번호: {case_number}\n"
                    f"선고일자: {decision_date}\n"
                    f"법원명: {court_name}\n"
                    f"사건종류명: {case_type}\n"
                    f"판결유형: {judgment_type}\n"
                    f"사건명: {case_name}\n\n"
                    f"{full_content}\n"
                    "==== PRECEDENT END ====\n\n"
                )

                f.write(block)
                print(f"[OK] prec_id={prec_id}")
                time.sleep(0.1)

    print(f"[DONE] saved TXT -> {OUTPUT_TXT}")


if __name__ == "__main__":
    main()
