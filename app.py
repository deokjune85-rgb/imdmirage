# ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1 â€” Domain ë©”ë‰´ ê°œì„  + Dual RAG (TXT/JSONL í•˜ì´ë¸Œë¦¬ë“œ)
# ======================================================

import streamlit as st
import google.generativeai as genai
import os
import re
import json
import numpy as np
import time

# ---------------------------------------
# 0. ê¸°ë³¸ ì„¸íŒ…
# ---------------------------------------
st.set_page_config(
    page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1",
    page_icon="ğŸ›¡ï¸",
    layout="centered"
)

# CSS ìŠ¤íƒ€ì¼
custom_css = """
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
.stChatMessage {border-radius:10px; padding:10px; margin-bottom:10px;}
.stChatMessage[data-testid="user"] {background:#e8f4f8;}
.stChatMessage[data-testid="assistant"] {background:#f0f0f0;}
.precedent-card {
    border: 1px solid #ddd;
    border-radius: 8px;
    padding: 12px;
    margin: 8px 0;
    background: #fafafa;
}
.precedent-card h4 {
    margin: 0 0 8px 0;
    color: #1f77b4;
}
.precedent-card .similarity {
    display: inline-block;
    background: #4CAF50;
    color: white;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 0.85em;
    margin-bottom: 6px;
}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# ìƒë‹¨ íƒ€ì´í‹€ + ê²½ê³ 
st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1")
st.caption("Phase 0: ë„ë©”ì¸ ì„ íƒ â†’ ì´í›„ Architectê°€ ìë™ ë¼ìš°íŒ…")

st.warning(
    "âš ï¸ **ë²•ë¥  ìë¬¸ ë©´ì±…**: ë³¸ ì‹œìŠ¤í…œì˜ ë¶„ì„ ê²°ê³¼ëŠ” ë²•ë¥  ìë¬¸ì´ ì•„ë‹ˆë©°, "
    "ì‹¤ì œ ë²•ë¥  ì‚¬ê±´ì—ëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
)

# ---------------------------------------
# 1. API í‚¤ ì„¤ì •
# ---------------------------------------
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    st.error("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloud Secretsì—ì„œ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

genai.configure(api_key=api_key)

# ---------------------------------------
# 2. ì„ë² ë”© / RAG ìœ í‹¸
# ---------------------------------------
EMBEDDING_MODEL_NAME = "models/text-embedding-004"


def embed_text(text: str, task_type: str = "retrieval_document"):
    """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    clean_text = text.replace("\n", " ").strip()
    if not clean_text:
        return None
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL_NAME,
            content=clean_text,
            task_type=task_type
        )
        return result["embedding"]
    except Exception as e:
        print(f"[Embedding error] {e}")
        return None


@st.cache_data(show_spinner=True)
def load_and_embed_data(file_path: str, separator_regex: str = None):
    """
    ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì„ë² ë”© ìƒì„±
    - .jsonl: ì¤„ ë‹¨ìœ„ JSON -> item['rag_index']ë¥¼ ì„ë² ë”©
    - .txt: separator_regex ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì„ë² ë”©
    """
    if not os.path.exists(file_path):
        print(f"[RAG] File not found: {file_path}")
        return [], []
    
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        print(f"[RAG] Error reading file: {e}")
        return [], []
    
    if not content.strip():
        return [], []

    data_items = []
    embeddings = []

    # JSONL íŒŒì¼ ì²˜ë¦¬
    if file_path.endswith(".jsonl"):
        for line in content.strip().split("\n"):
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except json.JSONDecodeError:
                continue
            
            txt = obj.get("rag_index") or obj.get("summary") or ""
            if not txt:
                continue
            
            emb = embed_text(txt, task_type="retrieval_document")
            if emb:
                data_items.append(obj)
                embeddings.append(emb)
    
    # TXT íŒŒì¼ ì²˜ë¦¬
    elif separator_regex:
        parts = re.split(separator_regex, content)
        for p in parts:
            p = p.strip()
            if not p:
                continue
            emb = embed_text(p, task_type="retrieval_document")
            if emb:
                data_items.append({"rag_index": p, "raw_text": p})
                embeddings.append(emb)
    
    print(f"[RAG] Loaded {len(data_items)} items from {file_path}")
    return data_items, embeddings


def find_similar_items(query_text, items, embeddings, top_k=3, threshold=0.5):
    """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ í•­ëª© ê²€ìƒ‰"""
    if not items or not embeddings:
        return []
    
    q_emb = embed_text(query_text, task_type="retrieval_query")
    if q_emb is None:
        return []
    
    sims = np.dot(np.array(embeddings), np.array(q_emb))
    idxs = np.argsort(sims)[::-1][:top_k]
    
    results = []
    for i in idxs:
        score = float(sims[i])
        if score < threshold:
            continue
        item = items[i].copy()
        item["similarity"] = score
        results.append(item)
    
    return results


# ---------------------------------------
# 3. ê°ì¢… ìœ í‹¸ í•¨ìˆ˜
# ---------------------------------------
def _is_menu_input(s: str) -> bool:
    """ë©”ë‰´ ì„ íƒ ì…ë ¥ì¸ì§€ í™•ì¸ (ì˜ˆ: 1, 2-3)"""
    return bool(re.fullmatch(r"^\s*\d{1,2}(?:-\d{1,2})?\s*$", s))


def _is_final_report(txt: str) -> bool:
    """ìµœì¢… ë³´ê³ ì„œì¸ì§€ í™•ì¸"""
    return "ì „ëµ ë¸Œë¦¬í•‘ ë³´ê³ ì„œ" in txt


def _query_title(prompt_text: str) -> str:
    """ì¿¼ë¦¬ ì œëª© ìƒì„± (70ì ì œí•œ)"""
    return prompt_text[:67] + "..." if len(prompt_text) > 70 else prompt_text


def update_active_module(response_text: str):
    """ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ í™œì„±í™”ëœ ëª¨ë“ˆ ì¶”ì¶œ ë° ì—…ë°ì´íŠ¸"""
    m = re.search(r"'(.*?)' ëª¨ë“ˆì„ (?:ìµœì¢… )?í™œì„±í™”í•©ë‹ˆë‹¤", response_text)
    if m:
        st.session_state.active_module = m.group(1).strip()
    elif "Phase 0" in response_text and not st.session_state.get("active_module"):
        st.session_state.active_module = "Phase 0 (ë„ë©”ì¸ ì„ íƒ)"


# ---------------------------------------
# 4. ì‹œìŠ¤í…œ í”„ë¼ì„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
# ---------------------------------------
try:
    with open("system_instruction.txt", "r", encoding="utf-8") as f:
        SYSTEM_INSTRUCTION = f.read()
except FileNotFoundError:
    st.error("system_instruction.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ---------------------------------------
# 5. Phase 0 â€” ë„ë©”ì¸ ì„ íƒ UI
# ---------------------------------------
domain_options = {
    "0": "ì„ íƒ ì•ˆ í•¨ (ìë™ íŒë‹¨)",
    "1": "í˜•ì‚¬",
    "2": "ë¯¼ì‚¬",
    "3": "ê°€ì‚¬/ì´í˜¼",
    "4": "í–‰ì •",
    "5": "ë…¸ë™",
    "6": "ë¶€ë™ì‚°",
    "7": "ì§€ì ì¬ì‚°",
    "8": "ì¡°ì„¸",
    "9": "ê¸°íƒ€(í˜¼í•©)",
}

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "selected_domain" not in st.session_state:
    st.session_state.selected_domain = "ì„ íƒ ì•ˆ í•¨ (ìë™ íŒë‹¨)"

st.subheader("Phase 0 â€” ì‚¬ê±´ ë„ë©”ì¸ ì„ íƒ")

# ë„ë©”ì¸ ì„ íƒì§€ í‘œì‹œ
domain_list = "\n".join([f"{k}. {v}" for k, v in domain_options.items()])
st.markdown(f"""
**í˜„ì¬ ì‚¬ê±´ì´ ì†í•œ ì£¼ ë„ë©”ì¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:**

{domain_list}

*ì„ íƒ ì•ˆ í•¨(0) ì‹œ ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.*
""")

selected_domain = st.session_state.selected_domain
st.info(f"í˜„ì¬ ë„ë©”ì¸ ì„¤ì •: **{selected_domain}**")

# ---------------------------------------
# 6. ëª¨ë¸ & ì„¸ì…˜ ì´ˆê¸°í™”
# ---------------------------------------
if "model" not in st.session_state:
    try:
        st.session_state.model = genai.GenerativeModel(
            "models/gemini-2.5-flash",
            system_instruction=SYSTEM_INSTRUCTION,
        )
        st.session_state.chat = st.session_state.model.start_chat(history=[])
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ (ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜): {e}")
        st.stop()

    st.session_state.messages = []
    st.session_state.active_module = f"Phase 0 â€” {selected_domain}"

    # RAG ì½”í¼ìŠ¤ ì§€ì—° ë¡œë”© ì„¤ì •
    st.session_state.precedents = []
    st.session_state.p_embeddings = []
    st.session_state.statutes = []
    st.session_state.s_embeddings = []

    # ì´ˆê¸° ì¸ì‚¬/ë°°ì¹˜
    try:
        domain_info = selected_domain
        if selected_domain == "ì„ íƒ ì•ˆ í•¨ (ìë™ íŒë‹¨)":
            domain_info = "ë¯¸ì •ì˜ (ì‹œìŠ¤í…œ ìë™ íŒë‹¨ í•„ìš”)"

        init_prompt = (
            f"ì‹œìŠ¤í…œ ê°€ë™. í˜„ì¬ ì„¤ì •ëœ ë„ë©”ì¸: {domain_info}. "
            f"Phase 0ì—ì„œ ì‚¬ê±´ êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³ , ì´í›„ Phase 1~ë¥¼ ë™ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ë¼. "
            f"ë§Œì•½ ë„ë©”ì¸ì´ ë¯¸ì •ì˜ë¼ë©´, ì‚¬ìš©ìì˜ ì²« ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë„ë©”ì¸ì„ íŒë‹¨í•˜ê³  í™œì„±í™”í•˜ë¼."
        )
        resp = st.session_state.chat.send_message(init_prompt)
        init_text = resp.text

        st.session_state.messages.append({"role": "user", "content": "(ì‹œìŠ¤í…œ ë¶€íŒ…)"})
        st.session_state.messages.append({"role": "Architect", "content": init_text})

        update_active_module(init_text)
    except Exception as e:
        st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ---------------------------------------
# 7. ê³¼ê±° ë©”ì‹œì§€ ë Œë”ë§
# ---------------------------------------
for m in st.session_state.messages:
    role_name = "Client" if m["role"] == "user" else "Architect"
    avatar_icon = "ğŸ‘¤" if m["role"] == "user" else "ğŸ›¡ï¸"
    with st.chat_message(role_name, avatar=avatar_icon):
        st.markdown(m["content"], unsafe_allow_html=True)

# ---------------------------------------
# 8. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í•¨ìˆ˜
# ---------------------------------------
def stream_and_store_response(chat_session, prompt_to_send: str,
                               spinner_text: str = "Architect ì‹œìŠ¤í…œ ì—°ì‚° ì¤‘..."):
    """LLM ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ì•„ì„œ í‘œì‹œí•˜ê³  ì €ì¥"""
    full_response = ""
    start_time = time.time()

    with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
        placeholder = st.empty()
        try:
            with st.spinner(spinner_text):
                stream = chat_session.send_message(prompt_to_send, stream=True)
                for chunk in stream:
                    # ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬
                    if not getattr(chunk, "parts", None) or not getattr(chunk, "text", None):
                        if not full_response:
                            full_response = "[ì‹œìŠ¤í…œ ê²½ê³ : ì‘ë‹µ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨.]"
                            placeholder.error(full_response)
                            break
                    full_response += chunk.text
                    placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
                placeholder.markdown(full_response, unsafe_allow_html=True)
        except Exception as e:
            full_response = f"[ì¹˜ëª…ì  ì˜¤ë¥˜: {e}]"
            placeholder.error(full_response)

    st.session_state.messages.append({"role": "Architect", "content": full_response})
    update_active_module(full_response)

    end_time = time.time()
    print(f"[LLM] ì‘ë‹µ ì‹œê°„: {end_time - start_time:.2f}s")
    return full_response


# ---------------------------------------
# 9. ë©”ì¸ ì…ë ¥ ë£¨í”„ + Dual RAG
# ---------------------------------------
if prompt := st.chat_input("ì‚¬ê±´ ì •ë³´ ë˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("Client", avatar="ğŸ‘¤"):
        st.markdown(prompt, unsafe_allow_html=True)

    # Phase ìƒíƒœ í™•ì¸
    is_data_ingestion_phase = "Phase 2" in (st.session_state.active_module or "")

    # RAG ë¹„í™œì„±í™” - ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ ì œê±°
    rag_context = ""
    similar_precedents = []

    # ë„ë©”ì¸ ë²ˆí˜¸ ì…ë ¥ ì²˜ë¦¬
    if prompt.strip() in domain_options:
        selected = domain_options[prompt.strip()]
        st.session_state.selected_domain = selected
        st.rerun()
    
    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    current_domain = st.session_state.selected_domain
    if current_domain == "ì„ íƒ ì•ˆ í•¨ (ìë™ íŒë‹¨)":
        current_domain = "ë¯¸ì •ì˜ (ì‹œìŠ¤í…œ ìë™ íŒë‹¨ í•„ìš”)"

    final_prompt = (
        f"[í˜„ì¬ ì„¤ì •ëœ ë„ë©”ì¸] {current_domain}\n"
        f"[ì‚¬ìš©ì ì›ë¬¸ ì…ë ¥]\n{prompt}\n"
    )

    # ì‹œìŠ¤í…œ ì‘ë‹µ ìƒì„±
    current_response = stream_and_store_response(
        st.session_state.chat,
        final_prompt,
    )

    # íŒë¡€ ì¹´ë“œ ì‹œê°í™”
    clean_response = re.sub("<[^<]+?>", "", current_response)

    if _is_final_report(clean_response) and similar_precedents:
        st.subheader("ğŸ“š ì°¸ê³  íŒë¡€ ìš”ì•½")
        for idx, prec in enumerate(similar_precedents, start=1):
            case_number = prec.get("case_number", f"íŒë¡€ {idx}")
            summary = prec.get("summary", prec.get("rag_index", "ìš”ì•½ ì—†ìŒ"))
            court = prec.get("court", "ë²•ì› ì •ë³´ ì—†ìŒ")
            date = prec.get("date", "ë‚ ì§œ ì •ë³´ ì—†ìŒ")
            similarity = prec.get("similarity", 0.0)
            full_text = prec.get("full_text", "ì „ë¬¸ ì—†ìŒ")

            card_html = f"""
            <div class="precedent-card">
                <h4>ğŸ“– {case_number}</h4>
                <span class="similarity">ìœ ì‚¬ë„: {similarity:.1%}</span>
                <p><strong>ë²•ì›:</strong> {court}</p>
                <p><strong>ì„ ê³ ì¼:</strong> {date}</p>
                <p><strong>ìš”ì§€:</strong> {summary[:300]}...</p>
            </div>
            """
            st.markdown(card_html, unsafe_allow_html=True)

            if full_text and full_text != "ì „ë¬¸ ì—†ìŒ":
                with st.expander("ğŸ“„ íŒë¡€ ì „ë¬¸ ë³´ê¸°"):
                    st.text(full_text)

    elif _is_final_report(clean_response) and not similar_precedents and not _is_menu_input(prompt):
        st.info(
            "â„¹ï¸ ë¶„ì„ê³¼ ê´€ë ¨ëœ ìœ ì‚¬ íŒë¡€ê°€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            "(ì„ê³„ê°’ 0.75)"
        )
