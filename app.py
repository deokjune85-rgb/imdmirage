# ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0 â€” Domain ë©”ë‰´ + Dual RAG (TXT/JSONL í•˜ì´ë¸Œë¦¬ë“œ)
# ======================================================
# ğŸ›¡ï¸ ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1 â€” Domain ë©”ë‰´ ê°œì„  + Dual RAG (TXT/JSONL í•˜ì´ë¸Œë¦¬ë“œ)
# ======================================================

import streamlit as st
import google.generativeai as genai
@@ -12,11 +14,12 @@
# 0. ê¸°ë³¸ ì„¸íŒ…
# ---------------------------------------
st.set_page_config(
    page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0",
    page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1",
page_icon="ğŸ›¡ï¸",
layout="centered"
)

# (CSS ë‚´ìš© ìœ ì§€)
custom_css = """
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
@@ -46,7 +49,7 @@
st.markdown(custom_css, unsafe_allow_html=True)

# ìƒë‹¨ íƒ€ì´í‹€ + ê²½ê³ 
st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0")
st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1")
st.caption("Phase 0: ë„ë©”ì¸ ì„ íƒ â†’ ì´í›„ Architectê°€ ìë™ ë¼ìš°íŒ…")

st.warning(
@@ -67,132 +70,81 @@
st.stop()

# ---------------------------------------
# 2. ì„ë² ë”© / RAG ìœ í‹¸
# 2. ì„ë² ë”© / RAG ìœ í‹¸ (ê¸°ì¡´ ìœ ì§€)
# ---------------------------------------
EMBEDDING_MODEL_NAME = "models/text-embedding-004"


def embed_text(text: str, task_type: str = "retrieval_document"):
clean_text = text.replace("\n", " ").strip()
    if not clean_text:
        return None
    if not clean_text: return None
try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL_NAME,
            content=clean_text,
            task_type=task_type,
        )
        result = genai.embed_content(model=EMBEDDING_MODEL_NAME, content=clean_text, task_type=task_type)
return result["embedding"]
except Exception as e:
        print(f"[Embedding error] {e}")
        return None

        print(f"[Embedding error] {e}"); return None

@st.cache_data(show_spinner=True)
def load_and_embed_data(file_path: str, separator_regex: str = None):
    """
    - .jsonl: ì¤„ ë‹¨ìœ„ JSON âœ item['rag_index']ë¥¼ ì„ë² ë”©
    - .txt  : separator_regex ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œì„œ ì„ë² ë”©
    """
    if not os.path.exists(file_path):
        print(f"[RAG] File not found: {file_path}")
        return [], []

    if not os.path.exists(file_path): return [], []
try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        print(f"[RAG] Error reading file: {e}")
        return [], []

    if not content.strip():
        return [], []
        with open(file_path, "r", encoding="utf-8") as f: content = f.read()
    except Exception: return [], []
    if not content.strip(): return [], []

    data_items = []
    embeddings = []

    # JSONL
    data_items, embeddings = [], []
if file_path.endswith(".jsonl"):
for line in content.strip().split("\n"):
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except json.JSONDecodeError:
                continue

            if not line.strip(): continue
            try: obj = json.loads(line.strip())
            except json.JSONDecodeError: continue
txt = obj.get("rag_index") or obj.get("summary") or ""
            if not txt:
                continue

            if not txt: continue
emb = embed_text(txt, task_type="retrieval_document")
            if emb:
                data_items.append(obj)
                embeddings.append(emb)

    # TXT
            if emb: data_items.append(obj); embeddings.append(emb)
elif separator_regex:
parts = re.split(separator_regex, content)
for p in parts:
p = p.strip()
            if not p:
                continue
            if not p: continue
emb = embed_text(p, task_type="retrieval_document")
            if emb:
                data_items.append({"rag_index": p, "raw_text": p})
                embeddings.append(emb)

            if emb: data_items.append({"rag_index": p, "raw_text": p}); embeddings.append(emb)
print(f"[RAG] Loaded {len(data_items)} items from {file_path}")
return data_items, embeddings


def find_similar_items(query_text, items, embeddings, top_k=3, threshold=0.5):
    if not items or not embeddings:
        return []

    if not items or not embeddings: return []
q_emb = embed_text(query_text, task_type="retrieval_query")
    if q_emb is None:
        return []

    if q_emb is None: return []
sims = np.dot(np.array(embeddings), np.array(q_emb))
idxs = np.argsort(sims)[::-1][:top_k]

results = []
for i in idxs:
score = float(sims[i])
        if score < threshold:
            continue
        if score < threshold: continue
item = items[i].copy()
item["similarity"] = score
results.append(item)

return results


# ---------------------------------------
# 3. ê°ì¢… ìœ í‹¸ í•¨ìˆ˜ (Phase íŒë‹¨ ë“±)
# 3. ê°ì¢… ìœ í‹¸ í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
# ---------------------------------------
def _is_menu_input(s: str) -> bool:
return bool(re.fullmatch(r"^\s*\d{1,2}(?:-\d{1,2})?\s*$", s))


def _is_final_report(txt: str) -> bool:
return "ì „ëµ ë¸Œë¦¬í•‘ ë³´ê³ ì„œ" in txt


def _query_title(prompt_text: str) -> str:
return prompt_text[:67] + "..." if len(prompt_text) > 70 else prompt_text


def update_active_module(response_text: str):
    m = re.search(r"\[(.+?)\]' ëª¨ë“ˆì„ í™œì„±í™”í•©ë‹ˆë‹¤", response_text)
    m = re.search(r"'(.*?)' ëª¨ë“ˆì„ (?:ìµœì¢… )?í™œì„±í™”í•©ë‹ˆë‹¤", response_text)
if m:
st.session_state.active_module = m.group(1).strip()
elif "Phase 0" in response_text and not st.session_state.get("active_module"):
st.session_state.active_module = "Phase 0 (ë„ë©”ì¸ ì„ íƒ)"


# ---------------------------------------
# 4. ì‹œìŠ¤í…œ í”„ë¼ì„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
# ---------------------------------------
@@ -206,9 +158,12 @@ def update_active_module(response_text: str):
st.stop()

# ---------------------------------------
# 5. Phase 0 â€” ë„ë©”ì¸ ì„ íƒ UI (ì—¬ê¸°ê°€ 'ì„ íƒì§€')
# 5. Phase 0 â€” ë„ë©”ì¸ ì„ íƒ UI (â˜…ìˆ˜ì •ë¨â˜…)
# ---------------------------------------
# [â˜…ìˆ˜ì •ë¨â˜…] "ì„ íƒ ì•ˆ í•¨" ì˜µì…˜ ì¶”ê°€
DEFAULT_OPTION = "ì„ íƒ ì•ˆ í•¨ (ìë™ íŒë‹¨)"
domain_options = [
    DEFAULT_OPTION,
"í˜•ì‚¬",
"ë¯¼ì‚¬",
"ê°€ì‚¬/ì´í˜¼",
@@ -220,49 +175,58 @@ def update_active_module(response_text: str):
"ê¸°íƒ€(í˜¼í•©)",
]

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì‹œ ê¸°ë³¸ê°’ ì„¤ì •
if "selected_domain" not in st.session_state:
    st.session_state.selected_domain = "í˜•ì‚¬"
    st.session_state.selected_domain = DEFAULT_OPTION

st.subheader("Phase 0 â€” ì‚¬ê±´ ë„ë©”ì¸ ì„ íƒ")

# ë¼ë””ì˜¤ ë²„íŠ¼ ìƒì„±
selected_domain = st.radio(
    "í˜„ì¬ ì‚¬ê±´ì´ ì†í•œ ì£¼ ë„ë©”ì¸ì„ ì„ íƒí•˜ì„¸ìš”.",
    "í˜„ì¬ ì‚¬ê±´ì´ ì†í•œ ì£¼ ë„ë©”ì¸ì„ ì„ íƒí•˜ì„¸ìš”. (ì„ íƒ ì•ˆ í•¨ ì‹œ ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.)",
domain_options,
    # í˜„ì¬ ì„¸ì…˜ ìƒíƒœì— ë”°ë¼ ì¸ë±ìŠ¤ ì„¤ì •
index=domain_options.index(st.session_state.selected_domain),
horizontal=True,
)

# ì„ íƒëœ ë„ë©”ì¸ ì—…ë°ì´íŠ¸
st.session_state.selected_domain = selected_domain
st.info(f"í˜„ì¬ ë„ë©”ì¸: **{selected_domain}**")
st.info(f"í˜„ì¬ ë„ë©”ì¸ ì„¤ì •: **{selected_domain}**")

# ---------------------------------------
# 6. ëª¨ë¸ & ì„¸ì…˜ ì´ˆê¸°í™”
# ---------------------------------------
if "model" not in st.session_state:
try:
st.session_state.model = genai.GenerativeModel(
            "models/gemini-2.5-flash",
            "models/gemini-2.5",
system_instruction=SYSTEM_INSTRUCTION,
)
st.session_state.chat = st.session_state.model.start_chat(history=[])
except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ (ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜): {e}")
st.stop()

st.session_state.messages = []
st.session_state.active_module = f"Phase 0 â€” {selected_domain}"

    # RAG ì½”í¼ìŠ¤ëŠ” 'ì§€ì—° ë¡œë”©' (ì²˜ìŒ ì§ˆë¬¸ ë“¤ì–´ì˜¬ ë•Œ)
    # RAG ì½”í¼ìŠ¤ ì§€ì—° ë¡œë”© ì„¤ì •
st.session_state.precedents = []
st.session_state.p_embeddings = []
st.session_state.statutes = []
st.session_state.s_embeddings = []

# ì´ˆê¸° ì¸ì‚¬/ë°°ì¹˜
try:
        # [â˜…ìˆ˜ì •ë¨â˜…] ì´ˆê¸° í”„ë¡¬í”„íŠ¸ì— ë„ë©”ì¸ ì •ë³´ ì „ë‹¬ ë°©ì‹ ê°œì„ 
        domain_info = selected_domain
        if selected_domain == DEFAULT_OPTION:
            domain_info = "ë¯¸ì •ì˜ (ì‹œìŠ¤í…œ ìë™ íŒë‹¨ í•„ìš”)"

init_prompt = (
            f"ì‹œìŠ¤í…œ ê°€ë™. í˜„ì¬ ì„ íƒëœ ë„ë©”ì¸: {selected_domain}. "
            f"Phase 0ì—ì„œ ì‚¬ê±´ êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³ , ì´í›„ Phase 1~ë¥¼ ë™ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ë¼."
            f"ì‹œìŠ¤í…œ ê°€ë™. í˜„ì¬ ì„¤ì •ëœ ë„ë©”ì¸: {domain_info}. "
            f"Phase 0ì—ì„œ ì‚¬ê±´ êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³ , ì´í›„ Phase 1~ë¥¼ ë™ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ë¼. ë§Œì•½ ë„ë©”ì¸ì´ ë¯¸ì •ì˜ë¼ë©´, ì‚¬ìš©ìì˜ ì²« ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë„ë©”ì¸ì„ íŒë‹¨í•˜ê³  í™œì„±í™”í•˜ë¼."
)
resp = st.session_state.chat.send_message(init_prompt)
init_text = resp.text
@@ -273,7 +237,7 @@ def update_active_module(response_text: str):
update_active_module(init_text)

# ---------------------------------------
# 7. ê³¼ê±° ë©”ì‹œì§€ ë Œë”ë§
# 7. ê³¼ê±° ë©”ì‹œì§€ ë Œë”ë§ (ìë™ ìŠ¤í¬ë¡¤ì€ Streamlit ê¸°ë³¸ ê¸°ëŠ¥)
# ---------------------------------------
for m in st.session_state.messages:
role_name = "Client" if m["role"] == "user" else "Architect"
@@ -282,38 +246,38 @@ def update_active_module(response_text: str):
st.markdown(m["content"], unsafe_allow_html=True)

# ---------------------------------------
# 8. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í•¨ìˆ˜
# 8. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€ ë° ê°œì„ )
# ---------------------------------------
def stream_and_store_response(chat_session, prompt_to_send: str,
spinner_text: str = "Architect ì‹œìŠ¤í…œ ì—°ì‚° ì¤‘..."):
full_response = ""
start_time = time.time()

with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
placeholder = st.empty()
try:
with st.spinner(spinner_text):
stream = chat_session.send_message(prompt_to_send, stream=True)
for chunk in stream:
                    if not getattr(chunk, "parts", None):
                        full_response = "[ì‹œìŠ¤í…œ ê²½ê³ : ì‘ë‹µì´ ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.]"
                    # ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬ ê°•í™”
                    if not getattr(chunk, "parts", None) or not getattr(chunk, "text", None):
                        # ì‘ë‹µì´ ì—†ê±°ë‚˜ ì•ˆì „ í•„í„°ì— ë§‰í˜”ì„ ê²½ìš° ì²˜ë¦¬
                        if not full_response: # ì²« ì‘ë‹µì´ ë§‰í˜”ì„ ê²½ìš°
                             full_response = "[ì‹œìŠ¤í…œ ê²½ê³ : ì‘ë‹µ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë¨.]"
placeholder.error(full_response)
break
full_response += chunk.text
placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
            placeholder.markdown(full_response, unsafe_allow_html=True)
                placeholder.markdown(full_response, unsafe_allow_html=True)
except Exception as e:
full_response = f"[ì¹˜ëª…ì  ì˜¤ë¥˜: {e}]"
placeholder.error(full_response)

    
st.session_state.messages.append({"role": "Architect", "content": full_response})
update_active_module(full_response)

end_time = time.time()
print(f"[LLM] ì‘ë‹µ ì‹œê°„: {end_time - start_time:.2f}s")
return full_response


# ---------------------------------------
# 9. ë©”ì¸ ì…ë ¥ ë£¨í”„ + Dual RAG
# ---------------------------------------
@@ -323,7 +287,7 @@ def stream_and_store_response(chat_session, prompt_to_send: str,
with st.chat_message("Client", avatar="ğŸ‘¤"):
st.markdown(prompt, unsafe_allow_html=True)

    # Phase ìƒíƒœ
    # Phase ìƒíƒœ í™•ì¸
is_data_ingestion_phase = "Phase 2" in (st.session_state.active_module or "")

# RAG ì½”í¼ìŠ¤ ì—†ìœ¼ë©´ ìµœì´ˆ 1íšŒ ë¡œë”©
@@ -340,10 +304,7 @@ def stream_and_store_response(chat_session, prompt_to_send: str,
# íŒë¡€ JSONL â†’ ì—†ìœ¼ë©´ TXT í´ë°±
p_data, p_emb = load_and_embed_data("precedents_data.jsonl")
if not p_data:
                st.warning(
                    "ê²½ê³ : 'precedents_data.jsonl' ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë¹„ì–´ ìˆìŒ. "
                    "'precedents_data.txt'ë¡œ í´ë°±í•©ë‹ˆë‹¤."
                )
                # (ê²½ê³  ë©”ì‹œì§€ ìƒëµ)
p_data, p_emb = load_and_embed_data(
"precedents_data.txt",
r"\s*---END OF PRECEDENT---\s*",
@@ -356,14 +317,19 @@ def stream_and_store_response(chat_session, prompt_to_send: str,
similar_precedents = []

if not _is_menu_input(prompt) and not is_data_ingestion_phase:
        # [â˜…ìˆ˜ì •ë¨â˜…] ë„ë©”ì¸ ì •ë³´ í™œìš© ê°œì„ 
        current_domain = st.session_state.selected_domain
        if current_domain == DEFAULT_OPTION:
            current_domain = "ë¯¸ì •ì˜ (ìë™ íŒë‹¨ ì¤‘)"

contextual_query = (
f"í˜„ì¬ í™œì„±í™”ëœ ëª¨ë“ˆ: {st.session_state.active_module}. "
            f"ì„ íƒëœ ë„ë©”ì¸: {st.session_state.selected_domain}. "
            f"ì‚¬ìš©ì ì§ˆë¬¸: {prompt}"
            f"ì„ íƒëœ ë„ë©”ì¸: {current_domain}. "
            f"ì‚¬ìš©ì ì§ˆë¬¸/ì‚¬ì‹¤ê´€ê³„: {prompt}"
)

with st.spinner("ì‹¤ì‹œê°„ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì¤‘... (Dual RAG: ë²•ë ¹/íŒë¡€)"):
            # ë²•ë ¹ ê²€ìƒ‰
            # ë²•ë ¹ ê²€ìƒ‰ (Threshold 0.75 ìœ ì§€)
if st.session_state.statutes:
s_hits = find_similar_items(
contextual_query,
@@ -383,7 +349,7 @@ def stream_and_store_response(chat_session, prompt_to_send: str,
"\n".join(s_texts)
)

            # íŒë¡€ ê²€ìƒ‰
            # íŒë¡€ ê²€ìƒ‰ (Threshold 0.75 ìœ ì§€)
if st.session_state.precedents:
similar_precedents = find_similar_items(
contextual_query,
@@ -403,18 +369,25 @@ def stream_and_store_response(chat_session, prompt_to_send: str,
"\n".join(p_texts)
)

    # ìµœì¢… í”„ë¡¬í”„íŠ¸
    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    # [â˜…ìˆ˜ì •ë¨â˜…] ë„ë©”ì¸ ì •ë³´ ì „ë‹¬ ë°©ì‹ ê°œì„ 
    current_domain = st.session_state.selected_domain
    if current_domain == DEFAULT_OPTION:
        current_domain = "ë¯¸ì •ì˜ (ì‹œìŠ¤í…œ ìë™ íŒë‹¨ í•„ìš”)"

final_prompt = (
        f"[ì„ íƒëœ ë„ë©”ì¸] {st.session_state.selected_domain}\n"
        f"[í˜„ì¬ ì„¤ì •ëœ ë„ë©”ì¸] {current_domain}\n"
f"[ì‚¬ìš©ì ì›ë¬¸ ì…ë ¥]\n{prompt}\n"
f"{rag_context}"
)
    
    # ì‹œìŠ¤í…œ ì‘ë‹µ ìƒì„±
current_response = stream_and_store_response(
st.session_state.chat,
final_prompt,
)

    # íŒë¡€ ì¹´ë“œ ì‹œê°í™”
    # íŒë¡€ ì¹´ë“œ ì‹œê°í™” (ê¸°ì¡´ ìœ ì§€)
clean_response = re.sub("<[^<]+?>", "", current_response)

if _is_final_report(clean_response) and similar_precedents:
@@ -455,7 +428,7 @@ def stream_and_store_response(chat_session, prompt_to_send: str,
with st.expander("ğŸ“„ íŒë¡€ ì „ë¬¸ ë³´ê¸°"):
st.text(full_text)

    elif _is_final_report(clean_response) and not similar_precedents:
    elif _is_final_report(clean_response) and not similar_precedents and not _is_menu_input(prompt):
st.info(
"â„¹ï¸ ë¶„ì„ê³¼ ê´€ë ¨ëœ ìœ ì‚¬ íŒë¡€ê°€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
"(ì„ê³„ê°’ 0.75)"
