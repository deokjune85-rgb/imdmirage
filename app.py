# ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0 â€” Domain ë©”ë‰´ + Dual RAG (TXT/JSONL í•˜ì´ë¸Œë¦¬ë“œ)

import streamlit as st
import google.generativeai as genai
import os
import numpy as np
import re
import time
import json

# ---------------------------------------
# 0. ê¸°ë³¸ ì„¸íŒ…
# ---------------------------------------
st.set_page_config(
    page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0",
    page_icon="ğŸ›¡ï¸",
    layout="centered"
)

custom_css = """
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
html, body, div, span, p {
    font-family: 'Noto Sans KR', sans-serif !important;
    font-size: 16px !important;
    line-height: 1.7 !important;
}
h1 {
    text-align: left !important;
    font-weight: 900 !important;
    font-size: 36px !important;
    margin-top: 10px !important;
    margin-bottom: 15px !important;
}
strong, b { font-weight: 700; }
.fadein { animation: fadeInText 0.5s ease-in-out forwards; opacity: 0; }
@keyframes fadeInText {
    from {opacity: 0; transform: translateY(3px);}
    to {opacity: 1; transform: translateY(0);}
}
[data-testid="stChatMessageContent"] {
    font-size: 16px !important;
}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# ìƒë‹¨ íƒ€ì´í‹€ + ê²½ê³ 
st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0")
st.caption("Phase 0: ë„ë©”ì¸ ì„ íƒ â†’ ì´í›„ Architectê°€ ìë™ ë¼ìš°íŒ…")

st.warning(
    "ë³´ì•ˆ ê²½ê³ : ë³¸ ì‹œìŠ¤í…œì€ ê²©ë¦¬ëœ ì‚¬ì„¤ í™˜ê²½(The Vault)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. "
    "ëª¨ë“  ë°ì´í„°ëŠ” ê¸°ë°€ë¡œ ì·¨ê¸‰ë˜ë©° ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
)

# ---------------------------------------
# 1. API í‚¤ ì„¤ì •
# ---------------------------------------
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    if not API_KEY:
        raise ValueError("API Key is empty.")
    genai.configure(api_key=API_KEY)
except (KeyError, ValueError) as e:
    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì—”ì§„ ì—°ê²° ì‹¤íŒ¨. {e}")
    st.stop()

# ---------------------------------------
# 2. ì„ë² ë”© / RAG ìœ í‹¸
# ---------------------------------------
EMBEDDING_MODEL_NAME = "models/text-embedding-004"


def embed_text(text: str, task_type: str = "retrieval_document"):
    clean_text = text.replace("\n", " ").strip()
    if not clean_text:
        return None
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL_NAME,
            content=clean_text,
            task_type=task_type,
        )
        return result["embedding"]
    except Exception as e:
        print(f"[Embedding error] {e}")
        return None


@st.cache_data(show_spinner=True)
def load_and_embed_data(file_path: str, separator_regex: str = None):
    """
    - .jsonl: ì¤„ ë‹¨ìœ„ JSON âœ item['rag_index']ë¥¼ ì„ë² ë”©
    - .txt  : separator_regex ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œì„œ ì„ë² ë”©
    """
    if not os.path.exists(file_path):
        print(f"[RAG] File not found: {file_path}")
        return [], []

    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        print(f"[RAG] Error reading file: {e}")
        return [], []

    if not content.strip():
        return [], []

    data_items = []
    embeddings = []

    # JSONL
    if file_path.endswith(".jsonl"):
        for line in content.strip().split("\n"):
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except json.JSONDecodeError:
                continue

            txt = obj.get("rag_index") or obj.get("summary") or ""
            if not txt:
                continue

            emb = embed_text(txt, task_type="retrieval_document")
            if emb:
                data_items.append(obj)
                embeddings.append(emb)

    # TXT
    elif separator_regex:
        parts = re.split(separator_regex, content)
        for p in parts:
            p = p.strip()
            if not p:
                continue
            emb = embed_text(p, task_type="retrieval_document")
            if emb:
                data_items.append({"rag_index": p, "raw_text": p})
                embeddings.append(emb)

    print(f"[RAG] Loaded {len(data_items)} items from {file_path}")
    return data_items, embeddings


def find_similar_items(query_text, items, embeddings, top_k=3, threshold=0.5):
    if not items or not embeddings:
        return []

    q_emb = embed_text(query_text, task_type="retrieval_query")
    if q_emb is None:
        return []

    sims = np.dot(np.array(embeddings), np.array(q_emb))
    idxs = np.argsort(sims)[::-1][:top_k]

    results = []
    for i in idxs:
        score = float(sims[i])
        if score < threshold:
            continue
        item = items[i].copy()
        item["similarity"] = score
        results.append(item)

    return results


# ---------------------------------------
# 3. ê°ì¢… ìœ í‹¸ í•¨ìˆ˜ (Phase íŒë‹¨ ë“±)
# ---------------------------------------
def _is_menu_input(s: str) -> bool:
    return bool(re.fullmatch(r"^\s*\d{1,2}(?:-\d{1,2})?\s*$", s))


def _is_final_report(txt: str) -> bool:
    return "ì „ëµ ë¸Œë¦¬í•‘ ë³´ê³ ì„œ" in txt


def _query_title(prompt_text: str) -> str:
    return prompt_text[:67] + "..." if len(prompt_text) > 70 else prompt_text


def update_active_module(response_text: str):
    m = re.search(r"\[(.+?)\]' ëª¨ë“ˆì„ í™œì„±í™”í•©ë‹ˆë‹¤", response_text)
    if m:
        st.session_state.active_module = m.group(1).strip()
    elif "Phase 0" in response_text and not st.session_state.get("active_module"):
        st.session_state.active_module = "Phase 0 (ë„ë©”ì¸ ì„ íƒ)"


# ---------------------------------------
# 4. ì‹œìŠ¤í…œ í”„ë¼ì„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
# ---------------------------------------
try:
    with open("system_prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_INSTRUCTION = f.read()
    if len(SYSTEM_INSTRUCTION) < 100:
        raise ValueError("System prompt is too short.")
except (FileNotFoundError, ValueError) as e:
    st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: system_prompt.txt ë¡œë“œ ì‹¤íŒ¨. {e}")
    st.stop()

# ---------------------------------------
# 5. Phase 0 â€” ë„ë©”ì¸ ì„ íƒ UI (ì—¬ê¸°ê°€ 'ì„ íƒì§€')
# ---------------------------------------
domain_options = [
    "í˜•ì‚¬",
    "ë¯¼ì‚¬",
    "ê°€ì‚¬/ì´í˜¼",
    "íŒŒì‚°Â·íšŒìƒ",
    "í–‰ì •/ì¡°ì„¸",
    "íšŒì‚¬Â·M&A",
    "ì˜ë£Œ/ì‚°ì¬",
    "IPÂ·ì €ì‘ê¶Œ",
    "ê¸°íƒ€(í˜¼í•©)",
]

if "selected_domain" not in st.session_state:
    st.session_state.selected_domain = "í˜•ì‚¬"

st.subheader("Phase 0 â€” ì‚¬ê±´ ë„ë©”ì¸ ì„ íƒ")

selected_domain = st.radio(
    "í˜„ì¬ ì‚¬ê±´ì´ ì†í•œ ì£¼ ë„ë©”ì¸ì„ ì„ íƒí•˜ì„¸ìš”.",
    domain_options,
    index=domain_options.index(st.session_state.selected_domain),
    horizontal=True,
)

st.session_state.selected_domain = selected_domain
st.info(f"í˜„ì¬ ë„ë©”ì¸: **{selected_domain}**")

# ---------------------------------------
# 6. ëª¨ë¸ & ì„¸ì…˜ ì´ˆê¸°í™”
# ---------------------------------------
if "model" not in st.session_state:
    try:
        st.session_state.model = genai.GenerativeModel(
            "models/gemini-2.5-flash",
            system_instruction=SYSTEM_INSTRUCTION,
        )
        st.session_state.chat = st.session_state.model.start_chat(history=[])
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

    st.session_state.messages = []
    st.session_state.active_module = f"Phase 0 â€” {selected_domain}"

    # RAG ì½”í¼ìŠ¤ëŠ” 'ì§€ì—° ë¡œë”©' (ì²˜ìŒ ì§ˆë¬¸ ë“¤ì–´ì˜¬ ë•Œ)
    st.session_state.precedents = []
    st.session_state.p_embeddings = []
    st.session_state.statutes = []
    st.session_state.s_embeddings = []

    # ì´ˆê¸° ì¸ì‚¬/ë°°ì¹˜
    try:
        init_prompt = (
            f"ì‹œìŠ¤í…œ ê°€ë™. í˜„ì¬ ì„ íƒëœ ë„ë©”ì¸: {selected_domain}. "
            f"Phase 0ì—ì„œ ì‚¬ê±´ êµ¬ì¡°ë¥¼ ìŠ¤ìº”í•˜ê³ , ì´í›„ Phase 1~ë¥¼ ë™ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ë¼."
        )
        resp = st.session_state.chat.send_message(init_prompt)
        init_text = resp.text
    except Exception as e:
        init_text = f"[ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}]"

    st.session_state.messages.append({"role": "Architect", "content": init_text})
    update_active_module(init_text)

# ---------------------------------------
# 7. ê³¼ê±° ë©”ì‹œì§€ ë Œë”ë§
# ---------------------------------------
for m in st.session_state.messages:
    role_name = "Client" if m["role"] == "user" else "Architect"
    avatar = "ğŸ‘¤" if m["role"] == "user" else "ğŸ›¡ï¸"
    with st.chat_message(role_name, avatar=avatar):
        st.markdown(m["content"], unsafe_allow_html=True)

# ---------------------------------------
# 8. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í•¨ìˆ˜
# ---------------------------------------
def stream_and_store_response(chat_session, prompt_t_
