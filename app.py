# =====================================================
# ğŸ›¡ï¸ ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 7.6 â€” Contextual Dual RAG (JSONL/TXT Hybrid) + Relay Mechanism
# =====================================================
import streamlit as st
import google.generativeai as genai
import os
import numpy as np
import re
import time
import json  # â˜… JSONL ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ ì¶”ê°€

# --- 1. ì‹œìŠ¤í…œ ì„¤ì • ë° CSS ---
st.set_page_config(page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 7.6", page_icon="ğŸ›¡ï¸", layout="centered")

# 'SaaS ì‚ë¼' ìƒˆë¼ë“¤ì˜ 'ì“°ë ˆê¸°' 'UI'ë¥¼ 'ì œê±°'í•˜ê³  'í°íŠ¸'ë¥¼ 'ê°•ì œ'í•œë‹¤.
custom_css = '''
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
html, body, div, span, p {
    font-family: "Noto Sans KR", sans-serif !important;
    font-size: 16px !important;
    line-height: 1.7 !important;
}
h1 { text-align: left !important; font-weight: 900 !important; font-size: 36px !important; margin-top: 10px !important; margin-bottom: 15px !important; }
strong, b { font-weight: 700; }
.fadein { animation: fadeInText 0.5s ease-in-out forwards; opacity: 0; }
@keyframes fadeInText { from {opacity: 0; transform: translateY(3px);} to {opacity: 1; transform: translateY(0);} }
[data-testid="stChatMessageContent"] { font-size: 16px !important; }
</style>
'''
st.markdown(custom_css, unsafe_allow_html=True)

# --- 2. íƒ€ì´í‹€ ë° ê²½ê³  ---
st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ ë²„ì „ 7.6")
st.warning("ë³´ì•ˆ ê²½ê³ : ë³¸ ì‹œìŠ¤í…œì€ ê²©ë¦¬ëœ ì‚¬ì„¤ í™˜ê²½(The Vault)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ëŠ” ê¸°ë°€ë¡œ ì·¨ê¸‰ë˜ë©° ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- 3. API í‚¤ ë° RAG ì—”ì§„ ì„¤ì • ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    if not API_KEY:
        raise ValueError("API Key is empty.")
    genai.configure(api_key=API_KEY)
except (KeyError, ValueError) as e:
    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì—”ì§„ ì—°ê²° ì‹¤íŒ¨. {e}")
    st.stop()

# --- [RAG ì—”ì§„ í•¨ìˆ˜ ì •ì˜] (â˜…í•µì‹¬ ìˆ˜ì •: JSONL/TXT í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”â˜…) ---
EMBEDDING_MODEL_NAME = "models/text-embedding-004"


def embed_text(text, task_type="retrieval_document"):
    """'í…ìŠ¤íŠ¸'ë¥¼ 'ë²¡í„°(ìˆ«ì)'ë¡œ 'ë³€í™˜'í•˜ëŠ” 'ì—°ê¸ˆìˆ '."""
    try:
        clean_text = text.replace("\n", " ").strip()
        if not clean_text:
            return None
        result = genai.embed_content(
            model=EMBEDDING_MODEL_NAME,
            content=clean_text,
            task_type=task_type
        )
        return result["embedding"]
    except Exception as e:
        print(f"Embedding error: {e}")
        return None


@st.cache_data(show_spinner=True)  # 'íƒ„ì•½ê³ ' 'ì¥ì „'ì€ 'ëˆˆ'ìœ¼ë¡œ 'í™•ì¸'ì‹œì¼œì¤€ë‹¤.
def load_and_embed_data(file_path, separator_regex=None):
    """
    'JSONL'ê³¼ 'TXT' 'íƒ„ì•½ê³ 'ë¥¼ 'ì½ì–´' 'ë²¡í„°' 'íƒ„ì•½'ìœ¼ë¡œ 'ì£¼ì¡°'í•œë‹¤.
    - íŒŒì¼ì´ ì•„ì˜ˆ ì—†ê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨: (None, None) ë°˜í™˜ â†’ ì§„ì§œ 'ë¡œë“œ ì‹¤íŒ¨'
    - íŒŒì¼ì€ ì½ì—ˆëŠ”ë° ì»¨í…ì¸  ì—†ìŒ: ([], []) ë°˜í™˜ â†’ íŒŒì¼ì€ ì •ìƒ, ë°ì´í„°ë§Œ ì—†ìŒ
    """
    # 1) íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    if not os.path.exists(file_path):
        print(f"[RAG] File not found: {file_path}")
        return None, None  # â˜… ì—¬ê¸°ì„œë§Œ 'ì§„ì§œ' ì‹¤íŒ¨ ì·¨ê¸‰

    # 2) íŒŒì¼ ì½ê¸°
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        print(f"[RAG] Error reading file {file_path}: {e}")
        return None, None  # â˜… ì½ê¸° ìì²´ê°€ ì•ˆ ë˜ë©´ ì´ê²ƒë„ 'ì§„ì§œ' ì‹¤íŒ¨

    if not content.strip():
        print(f"[RAG] File {file_path} is empty.")
        return [], []  # íŒŒì¼ì€ ìˆìœ¼ë‚˜ ë‚´ìš© ì—†ìŒ

    data_items, embeddings = [], []

    # 3) JSONL ëª¨ë“œ
    if file_path.endswith(".jsonl"):
        total_lines = 0
        parsed = 0
        embedded = 0

        for line_no, line in enumerate(content.strip().split("\n"), start=1):
            total_lines += 1
            line = line.strip()
            if not line:
                continue

            try:
                item = json.loads(line)
                parsed += 1
            except json.JSONDecodeError as e:
                print(f"[RAG][JSONL] Parse error {file_path}:{line_no} â†’ {e}")
                continue

            # 'rag_index' í•„ë“œë¥¼ 'ì„ë² ë”©' (í•µì‹¬!)
            text_to_embed = item.get("rag_index")
            if not text_to_embed:
                print(f"[RAG][JSONL] Missing 'rag_index' at {file_path}:{line_no}")
                continue

            ebd = embed_text(text_to_embed, task_type="retrieval_document")
            if ebd:
                embeddings.append(ebd)
                data_items.append(item)  # ì „ì²´ ê°ì²´ ì €ì¥
                embedded += 1
            else:
                print(f"[RAG][JSONL] Embedding failed at {file_path}:{line_no}")

        print(
            f"[RAG][JSONL] {file_path} â†’ lines={total_lines}, parsed={parsed}, embedded={embedded}"
        )

    # 4) TXT ëª¨ë“œ (ë²•ë ¹ ë°ì´í„° ë° í•˜ìœ„ í˜¸í™˜ì„±)
    elif separator_regex:
        chunks = re.split(separator_regex, content)
        raw_items = [p.strip() for p in chunks if p and p.strip()]
        print(f"[RAG][TXT] {file_path} â†’ chunks={len(raw_items)}")
        for item_text in raw_items:
            ebd = embed_text(item_text, task_type="retrieval_document")
            if ebd:
                embeddings.append(ebd)
                data_items.append({"rag_index": item_text, "raw_text": item_text})

    print(f"[RAG] Loaded {len(data_items)} items from {file_path}.")
    return data_items, embeddings


def find_similar_items(query_text, items, embeddings, top_k=3, threshold=0.50):
    """'ì‚¬ê±´'ê³¼ 'ê°€ì¥' 'ìœ ì‚¬í•œ' 'ì´ì•Œ' 3ê°œë¥¼ 'ë°œì‚¬'í•œë‹¤."""
    if not embeddings or not items:
        return []
    q_emb = embed_text(query_text, task_type="retrieval_query")
    if q_emb is None:
        return []

    # 'NumPy'ë¥¼ 'ì‚¬ìš©'í•œ 'ë²¡í„°' 'ë‚´ì ' 'ì—°ì‚°' (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    sims = np.dot(np.array(embeddings), np.array(q_emb))
    idxs = np.argsort(sims)[::-1][:top_k]

    results = []
    for i in idxs:
        if float(sims[i]) >= threshold:
            # 'ê²°ê³¼'ì— 'ì „ì²´' 'ê°ì²´'ì™€ 'ìœ ì‚¬ë„'ë¥¼ 'ì €ì¥'
            result_item = items[i].copy()
            result_item["similarity"] = float(sims[i])
            results.append(result_item)
    return results


# --- â˜…â˜…â˜… 'ì‚­ì œ'ëœ 'ìœ í‹¸ë¦¬í‹°' 'í•¨ìˆ˜' 'ì‹¬ì¥' 'ì´ì‹' â˜…â˜…â˜… ---
def _is_menu_input(s: str) -> bool:
    """'ì…ë ¥'ì´ 'ë‹¨ìˆœ' 'ìˆ«ì' 'ë©”ë‰´' 'ì„ íƒ'ì¸ì§€ 'íŒë‹¨'í•œë‹¤."""
    return bool(re.fullmatch(r"^\s*\d{1,2}(?:-\d{1,2})?\s*$", s))


def _is_final_report(txt: str) -> bool:
    """'ì‘ë‹µ'ì´ 'ìµœì¢… ë³´ê³ ì„œ' 'í˜•ì‹'ì¸ì§€ 'íŒë‹¨'í•œë‹¤."""
    return "ì „ëµ ë¸Œë¦¬í•‘ ë³´ê³ ì„œ" in txt


def _query_title(prompt_text: str) -> str:
    """'RAG' 'ì‹œê°í™”'ì— 'ì‚¬ìš©'í•  'ì¿¼ë¦¬' 'ì œëª©'ì„ 'ì¶”ì¶œ'í•œë‹¤."""
    if len(prompt_text) > 70:
        return prompt_text[:67] + "..."
    return prompt_text


def update_active_module(response_text):
    """'ë‡Œ(EPE)'ì˜ 'ì‘ë‹µ'ì—ì„œ 'í˜„ì¬' 'í™œì„±í™”'ëœ 'ëª¨ë“ˆ' 'ì´ë¦„'ì„ 'ì¶”ì¶œ'í•œë‹¤."""
    match = re.search(r"\[(.+?)\]' ëª¨ë“ˆì„ í™œì„±í™”í•©ë‹ˆë‹¤", response_text)
    if match:
        st.session_state.active_module = match.group(1).strip()
    elif "Phase 0" in response_text:
        st.session_state.active_module = "Phase 0 (ë„ë©”ì¸ ì„ íƒ)"


# --- 4. ì‹œìŠ¤í…œ í”„ë¼ì„ ìœ ì „ì (Prime Genome) ë¡œë“œ ë° ì´ˆê¸°í™” ---
try:
    with open("system_prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_INSTRUCTION = f.read()
    if len(SYSTEM_INSTRUCTION) < 100:
        raise ValueError("System prompt is too short.")
except (FileNotFoundError, ValueError) as e:
    st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ì‹œìŠ¤í…œ ì½”ì–´(system_prompt.txt) ë¡œë“œ ì‹¤íŒ¨. {e}")
    st.stop()

if "model" not in st.session_state:
    try:
        st.session_state.model = genai.GenerativeModel(
            "models/gemini-2.5-flash",
            system_instruction=SYSTEM_INSTRUCTION
        )

        # [â˜…ìˆ˜ì •ë¨â˜…] ë“€ì–¼ RAG ì´ˆê¸°í™” (JSONL + TXT)
        with st.spinner("ë¶„ì„ ì—”ì§„(Dual RA
