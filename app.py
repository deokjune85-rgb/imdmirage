import streamlit as st
import google.generativeai as genai

# --- 1. ì‹œìŠ¤í…œ ì„¤ì • (The Vault & Mirage Protocol) ---
st.set_page_config(page_title="ì•„ì´ì— ë”” ì•„í‚¤í…ì²˜ ë²„ì „ 7.0", page_icon="ğŸ›¡ï¸", layout="centered")

hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
header {visibility: hidden;}
.stDeployButton {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# --- 2. íƒ€ì´í‹€ ë° ê²½ê³  ---
st.title("ì•„ì´ì— ë”” ì•„í‚¤í…ì²˜ ë²„ì „ 7.0")
st.error("ë³´ì•ˆ ê²½ê³ : ë³¸ ì‹œìŠ¤í…œì€ ê²©ë¦¬ëœ ì‚¬ì„¤ í™˜ê²½(The Vault)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ëŠ” ê¸°ë°€ë¡œ ì·¨ê¸‰ë˜ë©° ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- 3. API í‚¤ ë° ëª¨ë¸ ì„¤ì • ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    st.error("ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì—”ì§„ ì—°ê²° ì‹¤íŒ¨. (API Key ëˆ„ë½)")
    st.stop()

genai.configure(api_key=API_KEY)

# ì™¸ë¶€ íŒŒì¼ ë¡œë“œ (system_prompt.txtì— í”„ë¼ì„ ê²Œë†ˆ ì „ì²´ ì €ì¥)
with open("system_prompt.txt", "r", encoding="utf-8") as f:
    SYSTEM_INSTRUCTION = f.read()

if "model" not in st.session_state:
    st.session_state.model = genai.GenerativeModel(
        'gemini-2.5-flash-latest',
        system_instruction=SYSTEM_INSTRUCTION
    )

# --- 4. ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬ ë° ìë™ ì‹œì‘ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "chat" not in st.session_state:
    st.session_state.chat = st.session_state.model.start_chat(history=[])
    
    initial_prompt = "ì‹œìŠ¤í…œ ê°€ë™. 'ë™ì  ë¼ìš°íŒ… í”„ë¡œí† ì½œ'ì„ ì‹¤í–‰í•˜ì—¬ Phase 0ë¥¼ ì‹œì‘í•˜ë¼."
    try:
        response = st.session_state.chat.send_message(initial_prompt)
        st.session_state.messages.append({"role": "Architect", "content": response.text})
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    role_name = "Client" if message["role"] == "user" else "Architect"
    avatar = "ğŸ‘¤" if message["role"] == "user" else "ğŸ›¡ï¸"
    with st.chat_message(role_name, avatar=avatar):
        st.markdown(message["content"])

# --- 5. ì‚¬ìš©ì ì…ë ¥ ë° ì‘ë‹µ ìƒì„± ---
if prompt := st.chat_input("ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹­ì‹œì˜¤."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("Client", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    with st.spinner("Architect ì‹œìŠ¤í…œ ì—°ì‚° ì¤‘..."):
        try:
            response_stream = st.session_state.chat.send_message(prompt, stream=True)
            with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
                response_placeholder = st.empty()
                full_response = ""
                for chunk in response_stream:
                    full_response += chunk.text
                    response_placeholder.markdown(full_response + "â–Œ")
                response_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "Architect", "content": full_response})
        except Exception as e:
            error_msg = f"ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_msg)
            st.session_state.messages.append({"role": "Architect", "content": error_msg})
