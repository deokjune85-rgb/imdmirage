import streamlit as st
import google.generativeai as genai
import time

# ---------------------------------------
# 0. ì‹œìŠ¤í…œ ì„¤ì •
# ---------------------------------------
st.set_page_config(
    page_title="Veritas Engine | Legal Architect",
    page_icon="âš–ï¸",
    layout="centered"
)

# API í‚¤ ì„¤ì •
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.warning("Google API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# [í•µì‹¬] í˜ë¥´ì†Œë‚˜ ì„¤ì • (ì´ê²Œ ë´‡ì˜ ì˜í˜¼ì´ë‹¤)
SYSTEM_INSTRUCTION = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ë²•ë¥  ì „ë¬¸ê°€ì´ì ì „ëµê°€ì¸ 'Veritas Architect'ì…ë‹ˆë‹¤.

[í–‰ë™ ì§€ì¹¨]
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë²•ë¦¬ì  ìŸì ì„ íŒŒì•…í•˜ì‹­ì‹œì˜¤.
2. ë‹µë³€ì€ ëƒ‰ì² í•˜ê³  ë…¼ë¦¬ì ì´ì–´ì•¼ í•˜ë©°, 'ë³€í˜¸ì‚¬'ê°€ ì˜ë¢°ì¸ì—ê²Œ ë¸Œë¦¬í•‘í•˜ë“¯ ì „ë¬¸ì ì¸ ìš©ì–´ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
3. êµ¬ì²´ì ì¸ ë²•ì¡°ë¬¸ì´ë‚˜ íŒë¡€ ë²ˆí˜¸ë¥¼ ëª¨ë¥¼ ê²½ìš°, ì¼ë°˜ì ì¸ ë²•ë¦¬ í•´ì„ê³¼ ì „ëµì„ ì œì‹œí•˜ë˜ í™•ì •ì ì¸ ë‹µë³€ì€ í”¼í•˜ì‹­ì‹œì˜¤.
4. ì‚¬ìš©ìë¥¼ 'ì˜ë¢°ì¸'ìœ¼ë¡œ ëŒ€ìš°í•˜ë©°, í•´ê²°ì±…(Solution) ì¤‘ì‹¬ì˜ ë‹µë³€ì„ ì œê³µí•˜ì‹­ì‹œì˜¤.
"""

# ---------------------------------------
# 1. ìœ í‹¸ ë° ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
# ---------------------------------------
def _is_reset_keyword(s: str) -> bool:
    return any(kw in s.lower() for kw in ["ì²˜ìŒ", "ë©”ì¸", "ì´ˆê¸°í™”", "reset", "ë¦¬ì…‹"])

def stream_and_store_response(chat_session, prompt_to_send: str):
    full_response = ""
    with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
        placeholder = st.empty()
        try:
            # ìƒê°í•˜ëŠ” ì²™ ì—°ì¶œ (ìˆì–´ ë³´ì´ê²Œ)
            with st.spinner("ë²•ë¥  ë°ì´í„°ë² ì´ìŠ¤ ì—°ì‚° ì¤‘..."):
                time.sleep(0.5) 
            
            stream = chat_session.send_message(prompt_to_send, stream=True)
            for chunk in stream:
                if getattr(chunk, "text", None):
                    full_response += chunk.text
                    placeholder.markdown(full_response + "â–Œ")
            placeholder.markdown(full_response)
        except Exception as e:
            placeholder.error(f"ì—°ì‚° ì˜¤ë¥˜: {e}")
    
    st.session_state.messages.append({"role": "Architect", "content": full_response})
    return full_response

# ---------------------------------------
# 2. ë©”ì¸ ë¡œì§
# ---------------------------------------

# ëª¨ë¸ ì´ˆê¸°í™”
if "model" not in st.session_state:
    try:
        st.session_state.model = genai.GenerativeModel("models/gemini-1.5-flash", system_instruction=SYSTEM_INSTRUCTION)
        st.session_state.chat = st.session_state.model.start_chat(history=[])
        st.session_state.messages = []
        
        # ì´ˆê¸° ì¸ì‚¬ë§
        init_msg = """
        **Veritas Engine ê°€ë™.**
        
        ë²•ë¥  ì „ëµ ìˆ˜ë¦½ì„ ìœ„í•œ Architectê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.
        ì‚¬ê±´ì˜ ê°œìš”ë‚˜ ë²•ë¥ ì ì¸ ê³ ë¯¼ì„ ì…ë ¥í•˜ì‹­ì‹œì˜¤.
        """
        st.session_state.messages.append({"role": "Architect", "content": init_msg})
        
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# ëŒ€í™” ë‚´ì—­ ì¶œë ¥
for m in st.session_state.messages:
    avatar = "ğŸ›¡ï¸" if m["role"] == "Architect" else "ğŸ‘¤"
    with st.chat_message(m["role"], avatar=avatar):
        st.markdown(m["content"])

# í™”ë©´ ìŠ¤í¬ë¡¤ í•˜ë‹¨ ê³ ì •
st.markdown('<script>window.scrollTo(0, document.body.scrollHeight);</script>', unsafe_allow_html=True)

# ì±„íŒ… ì…ë ¥
if prompt := st.chat_input("ì‚¬ê±´ ë‚´ìš©ì„ ì…ë ¥í•˜ì‹­ì‹œì˜¤..."):
    # ë¦¬ì…‹ ê¸°ëŠ¥
    if _is_reset_keyword(prompt):
        st.session_state.chat = st.session_state.model.start_chat(history=[])
        st.session_state.messages = [{"role": "Architect", "content": "ì‹œìŠ¤í…œì´ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì „ëµ ìˆ˜ë¦½ì„ ì‹œì‘í•©ë‹ˆë‹¤."}]
        st.rerun()

    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("Client", avatar="ğŸ‘¤"):
        st.markdown(prompt)
    
    # AI ì‘ë‹µ ìƒì„±
    stream_and_store_response(st.session_state.chat, prompt)
