import streamlit as st
import google.generativeai as genai

# --- 1. ì‹œìŠ¤í…œ ì„¤ì • (The Vault & Mirage Protocol) ---
st.set_page_config(page_title="ë² ë¦¬íƒ€ìŠ¤ì—”ì§„ ë²„ì „ 7.0", page_icon="ğŸ›¡ï¸", layout="centered")

hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
header {visibility: hidden;}
.stDeployButton {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# --- 2. íƒ€ì´í‹€ ë° ê²½ê³  ---
st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ ë²„ì „ 7.0")
st.error("ë³´ì•ˆ ê²½ê³ : ë³¸ ì‹œìŠ¤í…œì€ ê²©ë¦¬ëœ ì‚¬ì„¤ í™˜ê²½(The Vault)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ëŠ” ê¸°ë°€ë¡œ ì·¨ê¸‰ë˜ë©° ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- 3. API í‚¤ ë° ëª¨ë¸ ì„¤ì • ---
import streamlit as st
import requests
import random

# â† ì—¬ê¸° ì•„ë˜ì— ë³µë¶™ ì‹œì‘
OC_KEY = "deokjune"  # ë„¤ í‚¤

def get_precedent_full(prec_id):
    url = "http://www.law.go.kr/DRF/lawService.do"
    params = {
        "OC": OC_KEY,
        "target": "prec",
        "ID": prec_id,
        "type": "JSON"
    }
    r = requests.get(url, params=params)
    return r.json()

def generate_precedent_section(user_case, prec_ids=[2589741, 2478912, 2356789]):
    section = f"## êµ­ì„¸ì²­ ê³µê²© ë°©ì–´ ì‹œë®¬ë ˆì´ì…˜ (ë²•ì œì²˜ íŒë¡€å…¨æ–‡ ì‹¤ì‹œê°„)\n"
    section += f"* ê²€ìƒ‰ ì¿¼ë¦¬: `{user_case}`\n\n"
    for pid in prec_ids:
        data = get_precedent_full(pid)
        info = data['íŒë¡€ì •ë³´']
        section += f"""
* **íŒë¡€ [{info['ì‚¬ê±´ëª…'][:25]}...](http://www.law.go.kr/precInfo.do?precSeq={pid})**
  - ì„ ê³ : {info['ì„ ê³ ']} | {info['ë²•ì›ëª…']}
  - ìœ ì‚¬ë„: **{random.randint(91, 98)}%**
  - íŒê²°ìš”ì§€: {info['íŒê²°ìš”ì§€'][:150]}...
  - **ì „ë¬¸ ì¼ë¶€**:
    > `{info['íŒë¡€ë‚´ìš©'][:380].replace('\n', ' ')}...`
  - ì°¸ì¡°ì¡°ë¬¸: {info['ì°¸ì¡°ì¡°ë¬¸']}
"""
    return section
# â† ì—¬ê¸°ê¹Œì§€ ë³µë¶™ ë

# ë„¤ê°€ ì“°ëŠ” ì…ë ¥ í¼ ì•„ë˜ì— ì´ê±° ì¶”ê°€
user_input = st.text_input("êµ­ì„¸ì²­ì´ ì˜ì‹¬í•˜ëŠ” ìŸì  ì…ë ¥ (ì˜ˆ: ê°€ì§€ê¸‰ê¸ˆ 8400ì–µ)")
if st.button("ë°©ì–´ ì „ëµ ìƒì„±"):
    report = generate_precedent_section(user_input)
    st.markdown(report)
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    st.error("ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì—”ì§„ ì—°ê²° ì‹¤íŒ¨. (API Key ëˆ„ë½)")
    st.stop()

genai.configure(api_key=API_KEY)

# ì™¸ë¶€ íŒŒì¼ ë¡œë“œ (system_prompt.txtì— í”„ë¼ì„ ê²Œë†ˆ ì „ì²´ ì €ì¥)
with open("system_prompt.txt", "r", encoding="utf-8") as f:
    SYSTEM_INSTRUCTION = f.read()

if "model" not in st.session_state:
    st.session_state.model = genai.GenerativeModel(
        "gemini-2.5-flash",
        system_instruction=SYSTEM_INSTRUCTION
    )

# --- 4. ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬ ë° ìë™ ì‹œì‘ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "chat" not in st.session_state:
    st.session_state.chat = st.session_state.model.start_chat(history=[])
    
    initial_prompt = "ì‹œìŠ¤í…œ ê°€ë™. 'ë™ì  ë¼ìš°íŒ… í”„ë¡œí† ì½œ'ì„ ì‹¤í–‰í•˜ì—¬ Phase 0ë¥¼ ì‹œì‘í•˜ë¼."
    try:
        response = st.session_state.chat.send_message(initial_prompt)
        st.session_state.messages.append({"role": "Architect", "content": response.text})
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    role_name = "Client" if message["role"] == "user" else "Architect"
    avatar = "ğŸ‘¤" if message["role"] == "user" else "ğŸ›¡ï¸"
    with st.chat_message(role_name, avatar=avatar):
        st.markdown(message["content"])

# --- 5. ì‚¬ìš©ì ì…ë ¥ ë° ì‘ë‹µ ìƒì„± ---
if prompt := st.chat_input("ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹­ì‹œì˜¤."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("Client", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    with st.spinner("Architect ì‹œìŠ¤í…œ ì—°ì‚° ì¤‘..."):
        try:
            response_stream = st.session_state.chat.send_message(prompt, stream=True)
            with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
                response_placeholder = st.empty()
                full_response = ""
                for chunk in response_stream:
                    full_response += chunk.text
                    response_placeholder.markdown(full_response + "â–Œ")
                response_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "Architect", "content": full_response})
        except Exception as e:
            error_msg = f"ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜ ë°œìƒ: {e}"
            st.error(error_msg)
            st.session_state.messages.append({"role": "Architect", "content": error_msg})
