import streamlit as st
import google.generativeai as genai
import requests
import json
import numpy as np
from typing import List, Tuple
import os

# -----------------------------
# ê¸°ë³¸ ì„¸íŒ…
# -----------------------------
API_KEY = st.secrets.get("GOOGLE_API_KEY", os.environ.get("GOOGLE_API_KEY", ""))
if not API_KEY:
    raise RuntimeError("GOOGLE_API_KEY ë¥¼ st.secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— ë„£ì–´ì£¼ì„¸ìš”.")

genai.configure(api_key=API_KEY)

TXT_URL = "https://raw.githubusercontent.com/deokjune85-rgb/imdmirage/main/precedents_data.txt"

EMBED_MODEL = "models/text-embedding-004"
CHAT_MODEL  = "models/gemini-1.5-pro"


# -----------------------------
# 1. íŒë¡€ ë¡œë”© (txtë§Œ ì‚¬ìš©)
# -----------------------------
@st.cache_data(show_spinner="íŒë¡€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
def load_precedents() -> List[str]:
    r = requests.get(TXT_URL, timeout=30)
    if r.status_code != 200:
        raise RuntimeError(f"'precedents_data.txt' ë¡œë“œ ì‹¤íŒ¨ (status={r.status_code})")

    raw = r.text.strip()
    blocks = [b.strip() for b in raw.split("\n\n") if b.strip()]
    return blocks


# -----------------------------
# 2. íŒë¡€ ì„ë² ë”©
# -----------------------------
@st.cache_resource(show_spinner="íŒë¡€ ì„ë² ë”© ê³„ì‚° ì¤‘...")
def embed_precedents(precedents: List[str]) -> np.ndarray:
    if not precedents:
        return np.zeros((0, 0), dtype=np.float32)

    # ì„ë² ë”© ì°¨ì› í•œ ë²ˆ ì¡°íšŒ
    probe = genai.embed_content(
        model=EMBED_MODEL,
        content="ì„ë² ë”© í…ŒìŠ¤íŠ¸",
    )
    dim = len(probe["embedding"])

    embs: List[List[float]] = []
    for txt in precedents:
        try:
            res = genai.embed_content(
                model=EMBED_MODEL,
                content=txt,
            )
            embs.append(res["embedding"])
        except Exception:
            embs.append([0.0] * dim)

    return np.array(embs, dtype=np.float32)


def load_and_embed() -> Tuple[List[str], np.ndarray]:
    precedents = load_precedents()
    embeddings = embed_precedents(precedents)
    return precedents, embeddings


# -----------------------------
# 3. ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰
# -----------------------------
def search_similar_cases(
    query: str,
    precedents: List[str],
    embeddings: np.ndarray,
    top_k: int = 5,
) -> List[Tuple[int, float, str]]:
    if embeddings.size == 0 or not precedents:
        return []

    q_res = genai.embed_content(
        model=EMBED_MODEL,
        content=query,
    )
    q_emb = np.array(q_res["embedding"], dtype=np.float32)

    norms = np.linalg.norm(embeddings, axis=1) * (np.linalg.norm(q_emb) + 1e-8)
    sims = embeddings @ q_emb / (norms + 1e-8)

    idx_scores = list(enumerate(sims.tolist()))
    idx_scores.sort(key=lambda x: x[1], reverse=True)
    idx_scores = idx_scores[:top_k]

    results: List[Tuple[int, float, str]] = []
    for idx, score in idx_scores:
        results.append((idx, score, precedents[idx]))
    return results


def build_rag_context(similar_cases: List[Tuple[int, float, str]]) -> str:
    if not similar_cases:
        return ""

    parts = []
    for rank, (idx, score, text) in enumerate(similar_cases, start=1):
        parts.append(f"[ìœ ì‚¬ íŒë¡€ {rank}] (score={score:.3f})\n{text.strip()}")
    return "\n\n-----\n\n".join(parts)


# -----------------------------
# 4. LLM í˜¸ì¶œ
# -----------------------------
def call_llm(prompt: str) -> str:
    model = genai.GenerativeModel(CHAT_MODEL)
    resp = model.generate_content(prompt)
    return (resp.text or "").strip()


# -----------------------------
# 5. Streamlit UI
# -----------------------------
st.set_page_config(
    page_title="IMD Mirage Â· í˜•ì‚¬/ë¯¼ì‚¬ íŒë¡€ RAG ì—”ì§„",
    layout="wide",
)

st.title("IMD Mirage Â· í˜•ì‚¬/ë¯¼ì‚¬ íŒë¡€ RAG ì—”ì§„")

st.markdown(
    """
ì‚¬ì‹¤ê´€ê³„ì™€ ê³ ë¯¼ì„ ì•„ë˜ì— ì ìœ¼ë©´,  
ë‚´ë¶€ íŒë¡€ ë°ì´í„°(RAG)ë¥¼ ê²€ìƒ‰í•´ì„œ **ìœ ì‚¬ íŒë¡€ + ì¢…í•© ì½”ë©˜íŠ¸**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
)

if "precedents" not in st.session_state or "embeddings" not in st.session_state:
    with st.spinner("íƒ„ì•½ê³ (RAG) ì¥ì „ ì¤‘..."):
        p, e = load_and_embed()
        st.session_state.precedents = p
        st.session_state.embeddings = e

col_left, col_right = st.columns([2, 1])

with col_left:
    user_input = st.text_area(
        "â‘  ì‚¬ì‹¤ê´€ê³„ / ì‚¬ê±´ ê°œìš”ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        height=220,
        placeholder="ì˜ˆ) 2024. 5. 3. ë°¤ 11ì‹œê²½, ìˆ ìë¦¬ ì´í›„ ëŒ€ë¦¬ìš´ì „ í˜¸ì¶œí–ˆìœ¼ë‚˜...",
    )

    extra_instr = st.text_area(
        "â‘¡ ì¶”ê°€ ìš”ì²­(ë³´ê³ ì„œ í˜•ì‹, ë¶ˆê¸°ì†Œ ì „ëµ ê°•ì¡° ë“±)ì´ ìˆìœ¼ë©´ ì ì–´ì£¼ì„¸ìš”.",
        height=120,
        placeholder="ì˜ˆ) ë¶ˆê¸°ì†Œ(í˜ì˜ì—†ìŒ)ë¥¼ 1ìˆœìœ„ ëª©í‘œë¡œ, íŒë¡€ ì¸ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì˜ê²¬ì„œ êµ¬ì¡°ë¡œ ì¨ì¤˜.",
    )

    run_btn = st.button("âš–ï¸ íŒë¡€ ê²€ìƒ‰ + ì „ëµ ë¦¬í¬íŠ¸ ìƒì„±", type="primary")

with col_right:
    st.subheader("RAG ì˜µì…˜")
    top_k = st.slider("ìœ ì‚¬ íŒë¡€ ê°œìˆ˜", min_value=3, max_value=10, value=5, step=1)
    show_cases = st.checkbox("ìœ ì‚¬ íŒë¡€ ì›ë¬¸ë„ ê°™ì´ ë³´ê¸°", value=True)

    st.markdown("---")
    st.markdown("**RAG ìƒíƒœ**")
    st.write(f"íŒë¡€ ê°œìˆ˜: {len(st.session_state.precedents)}ê±´")
    st.write(f"ì„ë² ë”© shape: {tuple(st.session_state.embeddings.shape)}")

if run_btn and user_input.strip():
    precedents = st.session_state.precedents
    embeddings = st.session_state.embeddings

    with st.spinner("ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
        similar_cases = search_similar_cases(
            query=user_input,
            precedents=precedents,
            embeddings=embeddings,
            top_k=top_k,
        )
        rag_ctx = build_rag_context(similar_cases)

        system_guide = """
ë‹¹ì‹ ì€ í˜•ì‚¬/ë¯¼ì‚¬ ì „ë¬¸ ë³€í˜¸ì‚¬ë¥¼ ë³´ì¡°í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
1) ë¨¼ì € ì‚¬ê±´ì˜ 'í•µì‹¬ ìŸì 'ì„ ì •ë¦¬í•˜ê³ ,
2) RAGë¡œ ì œê³µëœ ìœ ì‚¬ íŒë¡€ë¥¼ ìš”ì•½Â·ë¹„êµí•œ ë’¤,
3) ì˜ë¢°ì¸ì´ ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” 'ì‹¤í–‰ ì „ëµ' ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
4) ê°ì • í˜¸ì†Œê°€ ì•„ë‹ˆë¼, ê°ê´€ì  ìë£ŒÂ·ë…¼ë¦¬ êµ¬ì¡° ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
"""
        full_prompt = (
            system_guide
            + "\n\n[ì‚¬ê±´ ê°œìš”]\n"
            + user_input.strip()
            + "\n\n[ì¶”ê°€ ìš”ì²­]\n"
            + (extra_instr.strip() or "íŠ¹ì´ ìš”ì²­ ì—†ìŒ.")
            + "\n\n[ë‚´ë¶€ ìœ ì‚¬ íŒë¡€ ëª¨ìŒ(RAG)]\n"
            + (rag_ctx or "ìœ ì‚¬ íŒë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë²•ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.")
        )

        answer = call_llm(full_prompt)

    st.subheader("ğŸ” ì¢…í•© ì „ëµ ë¦¬í¬íŠ¸")
    st.write(answer)

    if show_cases and similar_cases:
        st.subheader("ğŸ“š ì°¸ì¡°ëœ ìœ ì‚¬ íŒë¡€")
        for rank, (idx, score, text) in enumerate(similar_cases, start=1):
            with st.expander(f"ìœ ì‚¬ íŒë¡€ {rank} (score={score:.3f})"):
                st.write(text)

elif run_btn and not user_input.strip():
    st.warning("ì‚¬ê±´ ê°œìš”ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
