# =====================================================
# ğŸ›¡ï¸ ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0 â€” ì‹¤ì‹œê°„ íŒë¡€ API + ë²•ë ¹ RAG (TXT)
# =====================================================
import streamlit as st
import google.generativeai as genai
import requests
import xml.etree.ElementTree as ET
import os
import re
import numpy as np
import time
import json

# --- 1. ì‹œìŠ¤í…œ ì„¤ì • ---
st.set_page_config(page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.0", page_icon="ğŸ›¡ï¸", layout="centered")

custom_css = """
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
html, body, div, span, p {
    font-family: 'Noto Sans KR', sans-serif !important;
}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

st.title("ğŸ›¡ï¸ ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ v8.0 â€” ì‹¤ì‹œê°„ íŒë¡€ API ì ìš©")
st.warning("â€» ì´ ì‹œìŠ¤í…œì€ The Vault ë‚´ë¶€ ì „ìš©ì…ë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ëŠ” ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# --- 2. GOOGLE API KEY ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=API_KEY)
except:
    st.error("âŒ GOOGLE_API_KEY ì—†ìŒ")
    st.stop()

# =====================================================
# âš–ï¸ 3. ë²•ì œì²˜ íŒë¡€ API ì„¤ì • (OC ê¸°ë°˜)
# =====================================================
LAW_OC_ID = "deokjune"  # â† ì´ë¯¸ í™•ì¸ëœ ë„¤ OC
LAW_SEARCH_URL = "https://www.law.go.kr/DRF/mobPrecSearch.do"  # â† ë„¤ê°€ XML ë°›ì€ ì—”ë“œí¬ì¸íŠ¸

def search_precedents_from_api(keyword: str, page: int = 1, per_page: int = 20):
    """
    ğŸ” law.go.kr íŒë¡€ API ì‹¤ì‹œê°„ ê²€ìƒ‰
    """
    try:
        params = {
            "OC": LAW_OC_ID,
            "keyword": keyword,      # â€» ì¼ë¶€ ê³„ì •ì€ query=ì¨ì•¼ í•  ìˆ˜ ìˆìŒ
            "type": "XML",
            "page": page
        }

        resp = requests.get(LAW_SEARCH_URL, params=params, timeout=10)
        resp.raise_for_status()

        root = ET.fromstring(resp.text)
        results = []

        for prec in root.findall("prec"):
            pid = (prec.findtext("íŒë¡€ì¼ë ¨ë²ˆí˜¸") or "").strip()
            title = (prec.findtext("ì‚¬ê±´ëª…") or "").strip()
            case_no = (prec.findtext("ì‚¬ê±´ë²ˆí˜¸") or "").strip()
            date = (prec.findtext("ì„ ê³ ì¼ì") or "").strip()
            court = (prec.findtext("ë²•ì›ëª…") or "").strip()
            detail = (prec.findtext("íŒë¡€ìƒì„¸ë§í¬") or "").strip()

            if detail.startswith("http"):
                url = detail
            else:
                url = "https://www.law.go.kr" + detail

            rag_index = f"{court} {case_no} / {date}\n{title}\nì›ë¬¸: {url}"

            results.append({
                "id": pid,
                "title": title,
                "case_no": case_no,
                "court": court,
                "date": date,
                "url": url,
                "rag_index": rag_index,
                "similarity": 1.0,
            })

        return results

    except Exception as e:
        print(f"[íŒë¡€ API ì—ëŸ¬] {e}")
        return []


# =====================================================
# âš–ï¸ 4. ë²•ë ¹ RAG (statutes_data.txt)
# =====================================================
EMBEDDING_MODEL_NAME = "models/text-embedding-004"

def embed_text(text, task_type="retrieval_document"):
    try:
        clean = text.replace("\n", " ").strip()
        if not clean:
            return None
        res = genai.embed_content(
            model=EMBEDDING_MODEL_NAME,
            content=clean,
            task_type=task_type
        )
        return res["embedding"]
    except:
        return None

@st.cache_data(show_spinner=True)
def load_statutes(path="statutes_data.txt", separator=r"\s*---END OF STATUTE---\s*", max_items=300):
    """
    txt ë²•ë ¹ ë¡œë” â†’ ë¬¸ë‹¨ë³„ ì„ë² ë”©
    """
    if not os.path.exists(path):
        return [], []

    with open(path, "r", encoding="utf-8") as f:
        content = f.read()

    chunks = re.split(separator, content)
    chunks = [c.strip() for c in chunks if c.strip()][:max_items]

    items = []
    emb = []

    for c in chunks:
        e = embed_text(c)
        if e:
            items.append({"rag_index": c})
            emb.append(e)

    print(f"[ë²•ë ¹ RAG] {len(items)}ê°œ ë¡œë“œë¨")
    return items, emb


# =====================================================
# âš™ï¸ 5. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
# =====================================================
try:
    SYSTEM_PROMPT = open("system_prompt.txt", encoding="utf-8").read()
except:
    st.error("âŒ system_prompt.txt ì—†ìŒ")
    st.stop()


# =====================================================
# ğŸ¤– 6. ëª¨ë¸ ì´ˆê¸°í™”
# =====================================================
if "model" not in st.session_state:
    st.session_state.model = genai.GenerativeModel(
        "models/gemini-2.5-flash",
        system_instruction=SYSTEM_PROMPT
    )

    # ë²•ë ¹ë§Œ ë¡œë“œ (íŒë¡€ëŠ” APIë¡œ ì‹¤ì‹œê°„ ê²€ìƒ‰)
    with st.spinner("ë²•ë ¹ RAG ì´ˆê¸°í™” ì¤‘..."):
        S_DATA, S_EMB = load_statutes()
        st.session_state.statutes = S_DATA
        st.session_state.s_embeddings = S_EMB

    st.session_state.chat = st.session_state.model.start_chat(history=[])
    st.session_state.messages = []


# =====================================================
# ğŸ§  7. ìœ ì‚¬ ë²•ë ¹ ê²€ìƒ‰
# =====================================================
def find_similar_items(query_text, items, embeddings, top_k=3, threshold=0.75):
    if not items or not embeddings:
        return []
    q_emb = embed_text(query_text, "retrieval_query")
    if q_emb is None:
        return []

    sims = np.dot(np.array(embeddings), np.array(q_emb))
    idxs = np.argsort(sims)[::-1][:top_k]

    results = []
    for i in idxs:
        if float(sims[i]) >= threshold:
            d = items[i].copy()
            d["similarity"] = float(sims[i])
            results.append(d)

    return results


# =====================================================
# ğŸ’¬ 8. ë©”ì‹œì§€ ì¶œë ¥
# =====================================================
for m in st.session_state.messages:
    avatar = "ğŸ‘¤" if m["role"] == "user" else "ğŸ›¡ï¸"
    with st.chat_message(avatar):
        st.markdown(m["content"])


# =====================================================
# ğŸ§  9. ë©”ì¸ ì…ë ¥ ì²˜ë¦¬
# =====================================================
if prompt := st.chat_input("ì‚¬ê±´ ì„¤ëª… ë˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì‹­ì‹œì˜¤."):
    # --- ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ---
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("ğŸ‘¤"):
        st.markdown(prompt)

    rag_context = ""

    # 1) ë²•ë ¹ RAG
    statutes_found = find_similar_items(
        prompt,
        st.session_state.statutes,
        st.session_state.s_embeddings,
        top_k=3,
        threshold=0.75
    )
    if statutes_found:
        rag_context += "\n\n[ê´€ë ¨ ë²•ë ¹]\n"
        for s in statutes_found:
            rag_context += f"- {s['rag_index'][:200]}...\n"

    # 2) íŒë¡€ API (OC)
    with st.spinner("íŒë¡€ API ê²€ìƒ‰ ì¤‘..."):
        api_cases = search_precedents_from_api(prompt, page=1, per_page=10)

    if api_cases:
        rag_context += "\n\n[ì‹¤ì‹œê°„ ìœ ì‚¬ íŒë¡€]\n"
        for c in api_cases[:5]:
            rag_context += f"- {c['rag_index']}\n\n"

    # --- Gemini í”„ë¡¬í”„íŠ¸ ---
    final_prompt = f"{prompt}\n\n{rag_context}"

    # --- ëª¨ë¸ ì‘ë‹µ ---
    with st.chat_message("ğŸ›¡ï¸"):
        res = st.session_state.chat.send_message(final_prompt)
        st.markdown(res.text)
        st.session_state.messages.append({"role": "assistant", "content": res.text})
