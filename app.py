# -*- coding: utf-8 -*-
# ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1.3 â€” Auto-Analysis Mode + Dual RAG (ì½”ë“œ ë©¸ê·  ë° êµ¬ë¬¸ ë³µêµ¬ ì™„ë£Œ)

import streamlit as st
import google.generativeai as genai
import os
import numpy as np
import re
import time
import json
import PyPDF2 # PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìˆ˜

# ---------------------------------------
# 0. ê¸°ë³¸ ì„¸íŒ…
# ---------------------------------------
st.set_page_config(
    page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1",
    page_icon="ğŸ›¡ï¸",
    layout="centered"
)

# CSS (ëª¨ë“  ê³µë°±ì€ í‘œì¤€ ê³µë°± U+0020ìœ¼ë¡œ ì •ì œë¨)
custom_css = """
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
html, body, div, span, p {
    font-family: 'Noto Sans KR', sans-serif !important;
    font-size: 16px !important;
    line-height: 1.7 !important;
}
h1 {
    text-align: left !important;
    font-weight: 900 !important;
    font-size: 36px !important;
    margin-top: 10px !important;
    margin-bottom: 15px !important;
}
strong, b { font-weight: 700; }
.fadein { animation: fadeInText 0.5s ease-in-out forwards; opacity: 0; }
@keyframes fadeInText {
    from {opacity: 0; transform: translateY(3px);}
    to {opacity: 1; transform: translateY(0);}
}
[data-testid="stChatMessageContent"] {
    font-size: 16px !important;
}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1")
st.caption("The Architect â€” ì „ëµ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„")

# ì´ëª¨ì§€ ì œê±° ë° í…ìŠ¤íŠ¸ ìˆ˜ì • (í˜¸í™˜ì„± ê°•í™”)
st.warning(
    "ë³´ì•ˆ ê²½ê³ : ë³¸ ì‹œìŠ¤í…œì€ ê²©ë¦¬ëœ ì‚¬ì„¤ í™˜ê²½(The Vault)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. "
    "ëª¨ë“  ë°ì´í„°ëŠ” ê¸°ë°€ë¡œ ì·¨ê¸‰ë˜ë©° ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
)

# ---------------------------------------
# 1. API í‚¤ ì„¤ì •
# ---------------------------------------
try:
    # Streamlit Cloud ë°°í¬ ì‹œ st.secrets ì‚¬ìš©
    if "GOOGLE_API_KEY" in st.secrets:
        API_KEY = st.secrets["GOOGLE_API_KEY"]
    # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© (ì„ íƒ ì‚¬í•­)
    else:
        API_KEY = os.environ.get("GOOGLE_API_KEY")

    if not API_KEY:
        raise ValueError("API Key not found in secrets or environment variables.")
    genai.configure(api_key=API_KEY)
except (KeyError, ValueError) as e:
    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì—”ì§„ ì—°ê²° ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”. {e}")
    st.stop()

# ---------------------------------------
# 2. ì„ë² ë”© / RAG ìœ í‹¸
# ---------------------------------------
EMBEDDING_MODEL_NAME = "models/text-embedding-004"

def embed_text(text: str, task_type: str = "retrieval_document"):
    clean_text = text.replace("\n", " ").strip()
    if not clean_text:
        return None
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL_NAME,
            content=clean_text,
            task_type=task_type,
        )
        return result["embedding"]
    except Exception as e:
        print(f"[Embedding error] {e}")
        return None

# ---------------------------------------
# 2-1. ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”© ë¡œë“œ
# ---------------------------------------
@st.cache_data(show_spinner=False)
def load_precomputed_embeddings():
    """ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”© ë¡œë“œ (0.5ì´ˆ ì™„ë£Œ)"""
    statute_items = []
    statute_embeddings = []
    precedent_items = []
    precedent_embeddings = []
    
    # ë²•ë ¹ ë¡œë“œ
    if os.path.exists("statutes_embeddings.npy") and os.path.exists("statutes_items.json"):
        statute_embeddings = np.load("statutes_embeddings.npy").tolist()
        with open("statutes_items.json", "r", encoding="utf-8") as f:
            statute_items = json.load(f)
        print(f"[RAG] ë²•ë ¹ ë¡œë“œ ì™„ë£Œ: {len(statute_items)}ê°œ")
    
    # íŒë¡€ ë¡œë“œ
    if os.path.exists("precedents_embeddings.npy") and os.path.exists("precedents_items.json"):
        precedent_embeddings = np.load("precedents_embeddings.npy").tolist()
        with open("precedents_items.json", "r", encoding="utf-8") as f:
            precedent_items = json.load(f)
        print(f"[RAG] íŒë¡€ ë¡œë“œ ì™„ë£Œ: {len(precedent_items)}ê°œ")
    
    return statute_items, statute_embeddings, precedent_items, precedent_embeddings

def find_similar_items(query_text, items, embeddings, top_k=3, threshold=0.5):
    if not items or not embeddings:
        return []

    q_emb = embed_text(query_text, task_type="retrieval_query")
    if q_emb is None:
        return []

    # ì•ˆì •ì„±ì„ ìœ„í•´ ë°ì´í„° íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ ë³€í™˜
    try:
        embeddings_np = np.array(embeddings, dtype=np.float32)
        q_emb_np = np.array(q_emb, dtype=np.float32)
    except ValueError as e:
        print(f"[RAG Error] ì„ë² ë”© ë°ì´í„° íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}")
        return []

    # ì„ë² ë”© ì°¨ì› í™•ì¸ (ì•ˆì •ì„± ê°•í™”)
    if embeddings_np.size > 0:
        # ndim ì²´í¬ ì¶”ê°€í•˜ì—¬ 1ì°¨ì› ë°°ì—´ ì˜¤ë¥˜ ë°©ì§€
        if embeddings_np.ndim < 2 or embeddings_np.shape[1] != len(q_emb_np):
            print(f"[RAG Error] ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜ ë˜ëŠ” êµ¬ì¡° ì˜¤ë¥˜: DB Shape={embeddings_np.shape}, Query Len={len(q_emb_np)}")
            return []
    else:
        return []

    sims = np.dot(embeddings_np, q_emb_np)
    idxs = np.argsort(sims)[::-1][:top_k]

    results = []
    for i in idxs:
        score = float(sims[i])
        if score < threshold:
            continue
        item = items[i].copy()
        item["similarity"] = score
        results.append(item)

    return results

# ---------------------------------------
# 3. PDF ì²˜ë¦¬ í•¨ìˆ˜ (ì§„ë‹¨ ê°•í™”ë¨ v8.1.3)
# ---------------------------------------
def extract_text_from_pdf(uploaded_file):
    """PDF í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , ì‹¤íŒ¨ ì‹œ ì›ì¸ ì½”ë“œë¥¼ ë°˜í™˜í•œë‹¤."""
    try:
        # [ê°œì„  1] ì•ˆì •ì„± í™•ë³´: ìŠ¤íŠ¸ë¦¼ ìœ„ì¹˜ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¼ (Streamlit íŠ¹ì„± ê³ ë ¤)
        uploaded_file.seek(0)
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        
        # [ê°œì„  2] ì•”í˜¸í™” í™•ì¸
        if pdf_reader.is_encrypted:
             return "[ERROR:ENCRYPTED]"

        text = ""
        
        for page_num, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text()
            if page_text:
                # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì˜ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (ê³µë°± ì œê±°)
                cleaned_text = page_text.strip()
                if cleaned_text:
                    # í˜ì´ì§€ ë²ˆí˜¸ í‘œì‹œ (ì´ëª¨ì§€ ì œê±°)
                    text += f"\n--- í˜ì´ì§€ {page_num + 1} ---\n"
                    text += cleaned_text
        
        # [ê°œì„  3] ë‚´ìš©ë¬¼ ì—†ìŒ ê°ì§€ (ìŠ¤ìº” PDF ì§„ë‹¨)
        if not text.strip():
            # ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬ í›„ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ìŠ¤ìº”ëœ PDF ë˜ëŠ” ë¹ˆ íŒŒì¼ë¡œ ê°„ì£¼
            return "[ERROR:NO_TEXT]"

        return text.strip()
    
    except Exception as e:
        # ì²˜ë¦¬ ì‹¤íŒ¨ ê°ì§€ (ì†ìƒ ë“±)
        print(f"[PDF Extraction Error] {e}") # ë””ë²„ê¹…ìš© ì„œë²„ ë¡œê·¸
        return f"[ERROR:PROCESSING_FAILED]"


def analyze_case_file(pdf_text: str):
    """PDF í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•œë‹¤."""
    # â˜…â˜…â˜… [ì˜¤ë¥˜ ìˆ˜ì • ì™„ë£Œ] f-string ë¬¸ë²• ë° Markdown ì•„í‹°íŒ©íŠ¸ ì œê±° â˜…â˜…â˜…
    analysis_prompt = f"""
ë‹¤ìŒì€ ì‚¬ê±´ê¸°ë¡ PDFì—ì„œ ì¶”ì¶œí•œ ë‚´ìš©ì…ë‹ˆë‹¤.

[PDF ë‚´ìš©]
{pdf_text[:15000]} # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ê³ ë ¤

[ë¶„ì„ ì§€ì¹¨]
1. ì´ ì‚¬ê±´ì˜ ë„ë©”ì¸ ë¶„ë¥˜ (í˜•ì‚¬/ë¯¼ì‚¬/ê°€ì‚¬/í–‰ì •/íŒŒì‚°/IP/ì˜ë£Œ/ì„¸ë¬´ ì¤‘ 1ê°œ)
2. ì„¸ë¶€ ë¶„ì•¼ (ì˜ˆ: í˜•ì‚¬-ë§ˆì•½, ë¯¼ì‚¬-ê³„ì•½ë¶„ìŸ ë“±)
3. í•µì‹¬ ì‚¬ì‹¤ê´€ê³„ 5ê°€ì§€ (ì‹œê°„ìˆœ ë˜ëŠ” ì¤‘ìš”ë„ìˆœ)
4. í™•ë³´ëœ ì¦ê±° ëª©ë¡ (ë¬¸ì„œëª…, ì¢…ë¥˜)
5. í”¼ê³ ì¸/ì›ê³  ì¸¡ ì£¼ì¥ ìš”ì•½
6. ìƒëŒ€ë°© ì¸¡ ì£¼ì¥ ìš”ì•½

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”. (```json ë§ˆí¬ë‹¤ìš´ í¬í•¨)

```json
{{
  "domain": "í˜•ì‚¬",
  "subdomain": "ë§ˆì•½",
  "key_facts": ["ì‚¬ì‹¤ 1", "ì‚¬ì‹¤ 2", "ì‚¬ì‹¤ 3", "ì‚¬ì‹¤ 4", "ì‚¬ì‹¤ 5"],
  "evidence": ["ì¦ê±° 1", "ì¦ê±° 2"],
  "our_claim": "ìš°ë¦¬ ì¸¡ ì£¼ì¥ ìš”ì•½",
  "their_claim": "ìƒëŒ€ë°© ì¸¡ ì£¼ì¥ ìš”ì•½"
}}
""" # â˜…â˜…â˜… f-string ì •ìƒ ì¢…ë£Œë¨. ì•„ë˜ë¶€í„° ì •ìƒ ì½”ë“œ ì‹œì‘. â˜…â˜…â˜…

try:
    # [ìµœì í™”] ë¶„ì„ì—ëŠ” ì±„íŒ… ê¸°ë¡ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ, ë³„ë„ì˜ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (Gemini 1.5 Flash ê¶Œì¥)
    analysis_model = genai.GenerativeModel("models/gemini-1.5-flash-latest")
    response = analysis_model.generate_content(analysis_prompt)
    result_text = response.text.strip()
    
    # JSON ì¶”ì¶œ (ì •ê·œì‹ ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •ì„± ê°•í™”)
    json_match = re.search(r'```json\s*({.*?})\s*```', result_text, re.DOTALL)
    if json_match:
        json_str = json_match.group(1)
        result = json.loads(json_str)
        return result
    else:
        raise ValueError("AIê°€ ìœ íš¨í•œ JSON í˜•ì‹ì„ ìƒì„±í•˜ì§€ ëª»í•¨.")

except Exception as e:
    st.error(f"AI ë¶„ì„ ì‹¤íŒ¨: {e}")
    # ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹…ì„ ìœ„í•´ ì›ë³¸ ì‘ë‹µ ì¶œë ¥ (ì„œë²„ ë¡œê·¸)
    if 'response' in locals() and hasattr(response, 'text'):
        print(f"[Analysis Failure Debug] AI Response: {response.text[:1000]}")
    return None
---------------------------------------
4. ê°ì¢… ìœ í‹¸ í•¨ìˆ˜
---------------------------------------
def _is_menu_input(s: str) -> bool: return bool(re.fullmatch(r"^\s*\d{1,2}(?:-\d{1,2})?\s*$", s))

def _is_reset_keyword(s: str) -> bool: """ì²˜ìŒìœ¼ë¡œ/ë©”ì¸/ì´ˆê¸°í™” í‚¤ì›Œë“œ ê°ì§€""" keywords = ["ì²˜ìŒ", "ë©”ì¸", "ì´ˆê¸°í™”", "reset", "ëŒì•„ê°€", "ì²˜ìŒìœ¼ë¡œ"] return any(kw in s.lower() for kw in keywords)

def _is_final_report(txt: str) -> bool: return "ì „ëµ ë¸Œë¦¬í•‘ ë³´ê³ ì„œ" in txt

def _query_title(prompt_text: str) -> str: return prompt_text[:67] + "..." if len(prompt_text) > 70 else prompt_text

def update_active_module(response_text: str): # Auto-Analysis Mode ê°ì§€ (ì—„ê²©í•œ ì¡°ê±´) if ("9." in response_text and "ì‚¬ê±´ê¸°ë¡ ìë™ ë¶„ì„ ëª¨ë“œ" in response_text) or

("Auto-Analysis Modeë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤" in response_text): st.session_state.active_module = "Auto-Analysis Mode" return

# ì¼ë°˜ ëª¨ë“ˆ í™œì„±í™” (ì •ê·œì‹ ìˆ˜ì •: '[ëª¨ë“ˆëª…]' ë˜ëŠ” "'ëª¨ë“ˆëª…'" ëª¨ë‘ ê°ì§€)
m = re.search(r"['\[](.+?)['\]] ëª¨ë“ˆì„ (?:ìµœì¢… )?í™œì„±í™”í•©ë‹ˆë‹¤", response_text)
if m:
    st.session_state.active_module = m.group(1).strip()
elif "Phase 0" in response_text and not st.session_state.get("active_module"):
    st.session_state.active_module = "Phase 0"
---------------------------------------
5. ì‹œìŠ¤í…œ í”„ë¼ì„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
---------------------------------------
try: with open("system_prompt.txt", "r", encoding="utf-8") as f: SYSTEM_INSTRUCTION = f.read() if len(SYSTEM_INSTRUCTION) < 100: raise ValueError("System prompt is too short.") except (FileNotFoundError, ValueError) as e: st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: system_prompt.txt ë¡œë“œ ì‹¤íŒ¨. {e}") st.stop()

---------------------------------------
6. ëª¨ë¸ & ì„¸ì…˜ ì´ˆê¸°í™”
---------------------------------------
if "model" not in st.session_state: try: # ëª¨ë¸ëª… í‘œì¤€ìœ¼ë¡œ ìˆ˜ì • (gemini-1.5-flash-latest ê¶Œì¥) st.session_state.model = genai.GenerativeModel( "models/gemini-1.5-flash-latest", system_instruction=SYSTEM_INSTRUCTION, ) st.session_state.chat = st.session_state.model.start_chat(history=[]) except Exception as e: st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}") st.stop()

st.session_state.messages = []
st.session_state.active_module = "Phase 0"

# [ìµœì í™”] RAG ë°ì´í„°ëŠ” ì„¸ì…˜ ì‹œì‘ ì‹œ ì¦‰ì‹œ ë¡œë“œ (ì‚¬ì „ ì„ë² ë”© ì‚¬ìš©)
s_data, s_emb, p_data, p_emb = load_precomputed_embeddings()
st.session_state.statutes = s_data
st.session_state.s_embeddings = s_emb
st.session_state.precedents = p_data
st.session_state.p_embeddings = p_emb

# ì´ˆê¸° ì¸ì‚¬/ë°°ì¹˜
try:
    init_prompt = "ì‹œìŠ¤í…œ ê°€ë™. Phase 0ë¥¼ ì‹œì‘í•˜ë¼."
    resp = st.session_state.chat.send_message(init_prompt)
    init_text = resp.text
except Exception as e:
    init_text = f"[ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}]"

st.session_state.messages.append({"role": "Architect", "content": init_text})
update_active_module(init_text)
---------------------------------------
7. ê³¼ê±° ë©”ì‹œì§€ ë Œë”ë§ + ìë™ ìŠ¤í¬ë¡¤
---------------------------------------
for m in st.session_state.messages: role_name = "Client" if m["role"] == "user" else "Architect" avatar = "ğŸ‘¤" if m["role"] == "user" else "ğŸ›¡ï¸" with st.chat_message(role_name, avatar=avatar): st.markdown(m["content"], unsafe_allow_html=True)

ìë™ ìŠ¤í¬ë¡¤ JS ìŠ¤ë‹ˆí« (ë§¤ ë Œë”ë§ë§ˆë‹¤ ì‹¤í–‰)
if st.session_state.messages: st.markdown( '<script>setTimeout(()=>{const el=window.parent.document.querySelector("section.main");if(el)el.scrollTop=el.scrollHeight},100)</script>', unsafe_allow_html=True )

---------------------------------------
8. PDF ì—…ë¡œë“œ UI (Auto-Analysis Mode)
---------------------------------------
ì¡°ê±´: active_moduleì´ ì •í™•íˆ "Auto-Analysis Mode"ì´ê³ , 9ë²ˆì„ ì…ë ¥í•œ ì§í›„ì¼ ë•Œë§Œ í‘œì‹œ
if st.session_state.get("active_module") == "Auto-Analysis Mode": # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ê°€ "9"ì¸ì§€ í™•ì¸ last_user_msg = None for m in reversed(st.session_state.messages): if m["role"] == "user": last_user_msg = m["content"].strip() break

# 9ë²ˆ ì…ë ¥ ì§í›„ì—ë§Œ PDF UI í‘œì‹œ
if last_user_msg == "9":
    st.markdown("---")
    
    # ì •ë³´ ë°•ìŠ¤ (ì´ëª¨ì§€ ì œê±°)
    st.info("""
    **[ ì‚¬ê±´ê¸°ë¡ ìë™ ë¶„ì„ ëª¨ë“œ ]**
    
    PDF íŒŒì¼(íŒê²°ë¬¸, ê³ ì†Œì¥, ë‹µë³€ì„œ ë“±)ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìë™ìœ¼ë¡œ:
    - ì‚¬ê±´ ë„ë©”ì¸ ë¶„ë¥˜ (í˜•ì‚¬/ë¯¼ì‚¬/ê°€ì‚¬ ë“±)
    - í•µì‹¬ ì‚¬ì‹¤ê´€ê³„ 5ê°€ì§€ ì¶”ì¶œ
    - í™•ë³´ëœ ì¦ê±° ëª©ë¡ ì •ë¦¬
    - ì–‘ì¸¡ ì£¼ì¥ ìš”ì•½
    
    **ì²˜ë¦¬ ì‹œê°„:** ì•½ 1-3ë¶„ | **ìµœëŒ€ í¬ê¸°:** 50MB | **í˜•ì‹:** í…ìŠ¤íŠ¸ ê¸°ë°˜ PDFë§Œ ê°€ëŠ¥ (ìŠ¤ìº”ë³¸ ë¶ˆê°€)
    """)
    
    st.subheader("íŒŒì¼ ì—…ë¡œë“œ") # ì´ëª¨ì§€ ì œê±°
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            "ì‚¬ê±´ê¸°ë¡ PDFë¥¼ ì„ íƒí•˜ì„¸ìš”",
            type=["pdf"],
            help="íŒê²°ë¬¸, ê³ ì†Œì¥, ë‹µë³€ì„œ, ì‚¬ê±´ê¸°ë¡ ë“±",
            label_visibility="collapsed"
        )
    
    with col2:
        if uploaded_file:
            st.metric("ìƒíƒœ", "ì¤€ë¹„ ì™„ë£Œ", delta="ì—…ë¡œë“œ ì™„ë£Œ") # ì´ëª¨ì§€ ì œê±°
        else:
            st.metric("ìƒíƒœ", "ëŒ€ê¸° ì¤‘", delta="íŒŒì¼ ì„ íƒ") # ì´ëª¨ì§€ ì œê±°
    
    if uploaded_file is not None:
        file_size = uploaded_file.size / (1024 * 1024)
        
        # [ì£¼ì˜] ì´ ë¶€ë¶„ì˜ ë“¤ì—¬ì“°ê¸°ê°€ í•µì‹¬ì…ë‹ˆë‹¤. (NBSP ì œê±° ì™„ë£Œ)
        with st.container():
            st.success(f"**íŒŒì¼ëª…:** {uploaded_file.name}  |  **í¬ê¸°:** {file_size:.1f}MB")
        
        if st.button("ìë™ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True): # ì´ëª¨ì§€ ì œê±°
            # ìŠ¤í”¼ë„ˆ í…ìŠ¤íŠ¸ (ì´ëª¨ì§€ ì œê±°)
            with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘... (30ì´ˆ~2ë¶„ ì†Œìš”)"):
                # í•¨ìˆ˜ í˜¸ì¶œ ë° ê²°ê³¼ ë°›ê¸°
                pdf_text = extract_text_from_pdf(uploaded_file)
                
                # ìƒì„¸ ì˜¤ë¥˜ ì²˜ë¦¬ ë¡œì§ (v8.1.2)
                if not pdf_text or (isinstance(pdf_text, str) and pdf_text.startswith("[ERROR:")):
                    
                    if pdf_text == "[ERROR:NO_TEXT]":
                        st.error("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: PDFì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ìº”ëœ ì´ë¯¸ì§€ íŒŒì¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í…ìŠ¤íŠ¸ ê¸°ë°˜ PDFë§Œ ì§€ì›ë©ë‹ˆë‹¤.)")
                    
                    elif pdf_text == "[ERROR:ENCRYPTED]":
                        st.error("PDF ì²˜ë¦¬ ì‹¤íŒ¨: íŒŒì¼ì´ ì•”í˜¸í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì•”í˜¸ë¥¼ í•´ì œí•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

                    elif pdf_text == "[ERROR:PROCESSING_FAILED]":
                         st.error(f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    
                    else:
                        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë˜ëŠ” None ë°˜í™˜ ì‹œ
                        st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜)")
                    
                    st.stop()
                
                # ì„±ê³µ ì‹œ (pdf_textì— ë‚´ìš©ì´ ìˆìŒ)
                st.success(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(pdf_text):,} ê¸€ì)") # ì´ëª¨ì§€ ì œê±°
            
            # ë¶„ì„ ì‹¤í–‰
            # ìŠ¤í”¼ë„ˆ í…ìŠ¤íŠ¸ (ì´ëª¨ì§€ ì œê±°)
            with st.spinner("AI ë¶„ì„ ì¤‘... (1-2ë¶„ ì†Œìš”)"):
                # analyze_case_file í˜¸ì¶œ ì‹œ ëª¨ë¸ ì¸ì ì „ë‹¬í•˜ì§€ ì•ŠìŒ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìƒì„±)
                analysis = analyze_case_file(pdf_text)
                
                if not analysis:
                    # analyze_case_file ë‚´ë¶€ì—ì„œ ì´ë¯¸ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ë¨
                    st.stop()
            
            st.success("ë¶„ì„ ì™„ë£Œ!") # ì´ëª¨ì§€ ì œê±°
            
            # ê²°ê³¼ í‘œì‹œ
            # ìµìŠ¤íŒ¬ë” íƒ€ì´í‹€ (ì´ëª¨ì§€ ì œê±°)
            with st.expander("ë¶„ì„ ê²°ê³¼ ìƒì„¸ ë³´ê¸°", expanded=True):
                col_a, col_b = st.columns(2)
                
                # ë©”íŠ¸ë¦­ íƒ€ì´í‹€ (ì´ëª¨ì§€ ì œê±°)
                with col_a:
                    st.metric("ë„ë©”ì¸", analysis.get("domain", "ë¯¸ë¶„ë¥˜"))
                    st.metric("ì„¸ë¶€ ë¶„ì•¼", analysis.get("subdomain", "ë¯¸ë¶„ë¥˜"))
                
                with col_b:
                    st.metric("í•µì‹¬ ì‚¬ì‹¤", f"{len(analysis.get('key_facts', []))}ê°œ")
                    st.metric("ì¦ê±° í•­ëª©", f"{len(analysis.get('evidence', []))}ê°œ")
                
                st.markdown("---")
                st.markdown("**í•µì‹¬ ì‚¬ì‹¤ê´€ê³„**") # ì´ëª¨ì§€ ì œê±°
                for i, fact in enumerate(analysis.get("key_facts", []), 1):
                    st.markdown(f"{i}. {fact}")
                
                st.markdown("**í™•ë³´ëœ ì¦ê±°**") # ì´ëª¨ì§€ ì œê±°
                for i, ev in enumerate(analysis.get("evidence", []), 1):
                    st.markdown(f"{i}. {ev}")
                
                st.markdown("**ì–‘ì¸¡ ì£¼ì¥**") # ì´ëª¨ì§€ ì œê±°
                st.info(f"**ìš°ë¦¬ ì¸¡:** {analysis.get('our_claim', '(ì •ë³´ ì—†ìŒ)')}")
                st.warning(f"**ìƒëŒ€ ì¸¡:** {analysis.get('their_claim', '(ì •ë³´ ì—†ìŒ)')}")
            
                # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ (Phase 0 ë©”ë‰´ ê¸°ì¤€ ë§¤í•‘)
                domain_map = {
                    "í˜•ì‚¬": "2", "ë¯¼ì‚¬": "8", "ê°€ì‚¬": "1", "ì´í˜¼": "1",
                    "íŒŒì‚°": "3", "í–‰ì •": "7", "ì„¸ë¬´": "6", "IP": "4", "ì˜ë£Œ": "5",
                }
                
                domain_num = domain_map.get(analysis.get("domain"), "8") # ê¸°ë³¸ê°’ ë¯¼ì‚¬/ê¸°íƒ€
                
                # ì•ˆë‚´ ë°•ìŠ¤ (ì´ëª¨ì§€ ì œê±°)
                st.info(
                    f"**[ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ ]**\n\n"
                    f"ì´ ì‚¬ê±´ì€ **{analysis.get('domain', 'ë¯¸ë¶„ë¥˜')}** ì‚¬ê±´ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                    f"ê³„ì† ì§„í–‰í•˜ë ¤ë©´ ì•„ë˜ ì±„íŒ…ì°½ì— **{domain_num}**ì„ ì…ë ¥í•˜ì„¸ìš”."
                )
            
            # ì„¸ì…˜ ìƒíƒœì— ë¶„ì„ ê²°ê³¼ ì €ì¥
            st.session_state["auto_analysis"] = analysis
            st.session_state["pdf_text"] = pdf_text
    
    st.markdown("---")
---------------------------------------
9. ìë™ ë¶„ì„ ê²°ê³¼ í™œìš© UI
---------------------------------------
if "auto_analysis" in st.session_state and st.session_state.get("active_module") != "Auto-Analysis Mode": auto_data = st.session_state["auto_analysis"]

# ì•ˆë‚´ ë°•ìŠ¤ (ì´ëª¨ì§€ ì œê±°)
st.success(
    "**[ ìë™ ë¶„ì„ ê²°ê³¼ ê°ì§€ë¨ ]**\n\n"
    "ì‹œìŠ¤í…œì´ ë³€ìˆ˜ ì§ˆë¬¸ì„ ì‹œì‘í•˜ë©´, ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìë™ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# ë²„íŠ¼ í…ìŠ¤íŠ¸ (ì´ëª¨ì§€ ì œê±°)
if st.button("ìë™ ì…ë ¥ í™œì„±í™”", type="secondary", use_container_width=True):
    auto_input = f"""
[ìë™ ì¶”ì¶œëœ ì‚¬ê±´ ì •ë³´]

ë„ë©”ì¸: {auto_data.get('domain', 'ë¯¸ë¶„ë¥˜')} - {auto_data.get('subdomain', 'ë¯¸ë¶„ë¥˜')}

í•µì‹¬ ì‚¬ì‹¤ê´€ê³„: {chr(10).join(f"{i}. {fact}" for i, fact in enumerate(auto_data.get('key_facts', []), 1))}

í™•ë³´ëœ ì¦ê±°: {chr(10).join(f"- {ev}" for ev in auto_data.get('evidence', []))}

ìš°ë¦¬ ì¸¡ ì£¼ì¥: {auto_data.get('our_claim', '(ì •ë³´ ì—†ìŒ)')}

ìƒëŒ€ë°© ì£¼ì¥: {auto_data.get('their_claim', '(ì •ë³´ ì—†ìŒ)')}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ì§„í–‰í•´ì£¼ì„¸ìš”. """

    st.session_state.messages.append({"role": "user", "content": auto_input})
    # ë¶„ì„ ê²°ê³¼ ì‚¬ìš© í›„ ì„¸ì…˜ì—ì„œ ì œê±°
    del st.session_state["auto_analysis"]
    st.rerun()

st.markdown("---")
---------------------------------------
10. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í•¨ìˆ˜ (ì•ˆì •ì„± ê°•í™”)
---------------------------------------
def stream_and_store_response(chat_session, prompt_to_send: str, spinner_text: str = "Architect ì‹œìŠ¤í…œ ì—°ì‚° ì¤‘..."): full_response = "" start_time = time.time()

with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
    placeholder = st.empty()
    try:
        with st.spinner(spinner_text):
            stream = chat_session.send_message(prompt_to_send, stream=True)
            for chunk in stream:
                # ì•ˆì „ í•„í„° ë° ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬ ê°•í™”
                if not getattr(chunk, "text", None):
                    # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ í•„í„°ì— ê±¸ë¦° ê²½ìš°
                    if chunk.candidates and chunk.candidates[0].finish_reason == 'SAFETY':
                         full_response = "[ì‹œìŠ¤í…œ ê²½ê³ : ì‘ë‹µì´ ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.]"
                         placeholder.error(full_response)
                         break
                    elif hasattr(chunk, 'prompt_feedback') and chunk.prompt_feedback and chunk.prompt_feedback.block_reason:
                         full_response = f"[ì‹œìŠ¤í…œ ê²½ê³ : ì…ë ¥ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ìœ : {chunk.prompt_feedback.block_reason}]"
                         placeholder.error(full_response)
                         break
                    continue # í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ì²­í¬ëŠ” ë¬´ì‹œ

                full_response += chunk.text
                placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
        
        # ìµœì¢… ì‘ë‹µ í‘œì‹œ
        placeholder.markdown(full_response, unsafe_allow_html=True)
    
    except Exception as e:
        full_response = f"[ì¹˜ëª…ì  ì˜¤ë¥˜: {e}]"
        placeholder.error(full_response)

st.session_state.messages.append({"role": "Architect", "content": full_response})
update_active_module(full_response)

end_time = time.time()
print(f"[LLM] ì‘ë‹µ ì‹œê°„: {end_time - start_time:.2f}s")
return full_response
---------------------------------------
11. ë©”ì¸ ì…ë ¥ ë£¨í”„ + Dual RAG (ìµœì í™” ì ìš©)
---------------------------------------
if prompt := st.chat_input("ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹­ì‹œì˜¤"):

# 1. ì´ˆê¸°í™” í‚¤ì›Œë“œ ê°ì§€ (ìµœìš°ì„ )
if _is_reset_keyword(prompt):
    st.session_state.active_module = "Phase 0"
    # ê´€ë ¨ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "auto_analysis" in st.session_state: del st.session_state["auto_analysis"]
    if "pdf_text" in st.session_state: del st.session_state["pdf_text"]
    
    # Phase 0 ë©”ë‰´ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸° (ì±„íŒ… ì„¸ì…˜ ë° ë©”ì‹œì§€ ê¸°ë¡ ì™„ì „ ì´ˆê¸°í™”)
    try:
        st.session_state.chat = st.session_state.model.start_chat(history=[])
        init_prompt = "ì‹œìŠ¤í…œ ê°€ë™. Phase 0ë¥¼ ì‹œì‘í•˜ë¼."
        resp = st.session_state.chat.send_message(init_prompt)
        init_text = resp.text
        # ë©”ì‹œì§€ ê¸°ë¡ë„ ì´ˆê¸°í™” í›„ ì²« ë©”ì‹œì§€ë§Œ ì¶”ê°€
        st.session_state.messages = [{"role": "Architect", "content": init_text}]
    except Exception as e:
        st.error(f"[ì‹œìŠ¤í…œ ì¬ì‹œì‘ ì‹¤íŒ¨: {e}]")
        
    st.rerun()

# 2. 9ë²ˆ ì…ë ¥ ê°ì§€ (Auto-Analysis Mode ì§„ì…)
if prompt.strip() == "9":
    # Phase 0 ìƒíƒœì—ì„œë§Œ 9ë²ˆ ì…ë ¥ í—ˆìš© (ì•ˆì •ì„± ê°•í™”)
    if "Phase 0" not in st.session_state.active_module:
         st.warning("Auto-Analysis Mode(9ë²ˆ)ëŠ” Phase 0 ë©”ë‰´ì—ì„œë§Œ ì§„ì… ê°€ëŠ¥í•©ë‹ˆë‹¤. 'ì´ˆê¸°í™”'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        st.session_state.active_module = "Auto-Analysis Mode"
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("Client", avatar="ğŸ‘¤"):
            st.markdown(prompt, unsafe_allow_html=True)
        
        # AIì—ê²Œ 9ë²ˆ ì…ë ¥ ì „ë‹¬í•˜ì—¬ ëª¨ë“œ í™œì„±í™” ë©”ì‹œì§€ ë°›ê¸°
        response_text = stream_and_store_response(st.session_state.chat, prompt)
        st.rerun() # UI ê°±ì‹ í•˜ì—¬ PDF ì—…ë¡œë” í‘œì‹œ

# 3. ì¼ë°˜ ì±„íŒ… ì²˜ë¦¬
# ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡/í‘œì‹œ
st.session_state.messages.append({"role": "user", "content": prompt})
with st.chat_message("Client", avatar="ğŸ‘¤"):
    st.markdown(prompt, unsafe_allow_html=True)

# Phase ìƒíƒœ í™•ì¸
is_data_ingestion_phase = "Phase 2" in (st.session_state.active_module or "")

# RAG ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½
rag_context = ""
similar_precedents = []

# ë©”ë‰´ ì…ë ¥ì´ë‚˜ ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„ê°€ ì•„ë‹ ë•Œ RAG ì‹¤í–‰
if not _is_menu_input(prompt) and not is_data_ingestion_phase:
    
    # Contextual Query ìƒì„±
    contextual_query = f"í˜„ì¬ í™œì„±í™”ëœ ëª¨ë“ˆ: {st.session_state.active_module}. ì‚¬ìš©ì ì§ˆë¬¸/ì…ë ¥: {prompt}"

    # Dual RAG ì‹¤í–‰
    # ìŠ¤í”¼ë„ˆ í…ìŠ¤íŠ¸ (ì´ëª¨ì§€ ì œê±°)
    with st.spinner("ì‹¤ì‹œê°„ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì¤‘... (Dual RAG: ë²•ë ¹/íŒë¡€)"):
        # ë²•ë ¹ ê²€ìƒ‰ (S-RAG) - [ìµœì í™”] ì„ê³„ê°’ 0.65ë¡œ í•˜í–¥ ì¡°ì •
        if st.session_state.statutes:
            s_hits = find_similar_items(
                contextual_query,
                st.session_state.statutes,
                st.session_state.s_embeddings,
                top_k=3,
                threshold=0.65, # ë²•ë ¹ì€ ì¶”ìƒì ì´ë¯€ë¡œ ê¸°ì¤€ ì™„í™”
            )
            if s_hits:
                s_texts = [
                    f"[ìœ ì‚¬ë„: {hit['similarity']:.2f}]\n"
                    f"{hit.get('rag_index', 'ë‚´ìš© ì—†ìŒ')}\n---\n"
                    for hit in s_hits
                ]
                rag_context += (
                    "\n\n[ì‹œìŠ¤í…œ ì°¸ì¡°: ê²€ìƒ‰ëœ ê´€ë ¨ ë²•ë ¹ ë°ì´í„°]\n" +
                    "\n".join(s_texts)
                )

        # íŒë¡€ ê²€ìƒ‰ (P-RAG) - [ìµœì í™”] ì„ê³„ê°’ 0.75 ìœ ì§€
        if st.session_state.precedents:
            similar_precedents = find_similar_items(
                contextual_query,
                st.session_state.precedents,
                st.session_state.p_embeddings,
                top_k=5,
                threshold=0.75, # íŒë¡€ëŠ” êµ¬ì²´ì ì´ë¯€ë¡œ ê¸°ì¤€ ìœ ì§€
            )
            if similar_precedents:
                p_texts = [
                    f"[ìœ ì‚¬ë„: {hit['similarity']:.2f}]\n"
                    f"{hit.get('rag_index', 'ë‚´ìš© ì—†ìŒ')}\n---\n"
                    for hit in similar_precedents
                ]
                rag_context += (
                    "\n\n[ì‹œìŠ¤í…œ ì°¸ì¡°: ê²€ìƒ‰ëœ ìœ ì‚¬ íŒë¡€ ë°ì´í„°]\n" +
                    "\n".join(p_texts)
                )

# ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ ë° ì „ì†¡
final_prompt = (
    f"[ì‚¬ìš©ì ì›ë¬¸ ì…ë ¥]\n{prompt}\n"
    f"{rag_context}"
)

current_response = stream_and_store_response(st.session_state.chat, final_prompt)

# íŒë¡€ ì¹´ë“œ ì‹œê°í™” (ë³´ê³ ì„œ ìƒì„± ì‹œì—ë§Œ)
clean_response = re.sub("<[^<]+?>", "", current_response)

if _is_final_report(clean_response) and similar_precedents:
    q_title = _query_title(prompt)
    # íƒ€ì´í‹€ (ì´ëª¨ì§€ ì œê±°)
    st.markdown(
        f"**[ ì‹¤ì‹œê°„ íŒë¡€ ì „ë¬¸ ë¶„ì„ (P-RAG ê²°ê³¼) ]**\n\n"
        f"* ê²€ìƒ‰ ì¿¼ë¦¬: `[{q_title}]`\n"
    )

    for case_data in similar_precedents[:3]:
        sim_pct = int(round(case_data["similarity"] * 100))

        title = case_data.get("title", "ì œëª© ì—†ìŒ")
        case_no = case_data.get("case_no", case_data.get("id", ""))
        court = case_data.get("court", "")
        date = case_data.get("date", "")
        url = case_data.get("url")
        full_text = case_data.get("full_text", case_data.get("raw_text"))

        label = f"íŒë¡€ [{title}]"
        if court and case_no:
            label += f" â€” {court} {case_no}"

        summary = case_data.get("rag_index", "ìš”ì•½ ë‚´ìš© ì—†ìŒ")
        if len(summary) > 200:
            summary = summary[:197] + "..."

        # ë§í¬ í…ìŠ¤íŠ¸ (ì´ëª¨ì§€ ì œê±°)
        link_md = f"[ì›ë¬¸ ë§í¬ ë³´ê¸°]({url})" if url else ""

        md = (
            f"* **{label}**\n"
            f"  - ì„ ê³ : {date} | ìœ ì‚¬ë„: {sim_pct}% | {link_md}\n"
            f"  - ë‚´ìš© ìš”ì•½: {summary}"
        )
        st.markdown(md)

        if full_text:
            # ìµìŠ¤íŒ¬ë” íƒ€ì´í‹€ (ì´ëª¨ì§€ ì œê±°)
            with st.expander("íŒë¡€ ì „ë¬¸ ë³´ê¸°"):
                st.text(full_text)

elif _is_final_report(clean_response) and not similar_precedents:
    # ì•ˆë‚´ ë°•ìŠ¤ (ì´ëª¨ì§€ ì œê±°)
    st.info(
        "ì•ˆë‚´: ë¶„ì„ê³¼ ê´€ë ¨ëœ ìœ ì‚¬ íŒë¡€ê°€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
        "(ì„ê³„ê°’ 0.75)"
    )
