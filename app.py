# ======================================================
# ğŸ›¡ï¸ Veritas Engine v7.8 â€” Full Dark Clean Mode
# ======================================================
import streamlit as st
import google.generativeai as genai
import requests, re, os, numpy as np

# ======================================================
# 1. SYSTEM CONFIG
# ======================================================
st.set_page_config(page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ v7.8", page_icon="ğŸ›¡ï¸", layout="centered")

# === ğŸ’¡ ì „ì—­ ë””ìì¸ CSS (ê¸€ììƒ‰ í°ìƒ‰ + ì‚¬ì´ì¦ˆ í†µì¼ + ë§ˆí¬ë‹¤ìš´ ì •ë ¬) ===
st.markdown("""
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', sans-serif !important;
    font-size: 16px !important;
    line-height: 1.7 !important;
    color: #FFFFFF !important;
    background-color: #0E1117 !important;
}
[data-testid="stChatMessageContent"] {
    font-family: 'Noto Sans KR', sans-serif !important;
    font-size: 16px !important;
    color: #FFFFFF !important;
    line-height: 1.7 !important;
    white-space: pre-wrap !important;
}
h1, h2, h3, h4, h5, h6 {
    color: #FFFFFF !important;
    font-weight: 700 !important;
}
.stMarkdown p {
    color: #FFFFFF !important;
    font-size: 16px !important;
    line-height: 1.7 !important;
}
hr {border: none !important; border-top: 1px solid #444 !important;}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ›¡ï¸ ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ ë²„ì „ 7.8")
st.error("ë³´ì•ˆ ê²½ê³ : ë³¸ ì‹œìŠ¤í…œì€ ê²©ë¦¬ëœ ì‚¬ì„¤ í™˜ê²½(The Vault)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ëŠ” ê¸°ë°€ë¡œ ì·¨ê¸‰ë˜ë©° ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ======================================================
# 2. API KEYS
# ======================================================
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
except KeyError:
    st.error("ì‹œìŠ¤í…œ ì˜¤ë¥˜: 'GOOGLE_API_KEY' ëˆ„ë½. [Secrets] íƒ­ì„ í™•ì¸í•˜ë¼.")
    st.stop()

genai.configure(api_key=API_KEY)

try:
    OC_KEY = st.secrets["LAW_API_KEY"]
except KeyError:
    OC_KEY = "DEOKJUNE"

# ======================================================
# 3. ë²•ì œì²˜ API ìíŒê¸°
# ======================================================
def get_precedent_full(prec_id):
    url = "http://www.law.go.kr/DRF/lawService.do"
    params = {"OC": OC_KEY, "target": "prec", "ID": prec_id, "type": "JSON"}
    try:
        r = requests.get(url, params=params, timeout=10)
        data = r.json()
        if 'íŒë¡€ì •ë³´' not in data:
            return {"error": "API ì‘ë‹µ êµ¬ì¡° ì´ìƒ"}
        return data
    except Exception as e:
        return {"error": f"API ì‹¤íŒ¨: {e}"}

def show_full_precedent(prec_id):
    data = get_precedent_full(prec_id)
    if "error" in data:
        return f"---\n**[API ë¶„ì„ ì‹¤íŒ¨]** (ID: {prec_id})\n{data['error']}\n---"
    try:
        info = data.get('íŒë¡€ì •ë³´', {})
        title = info.get('ì‚¬ê±´ëª…', 'N/A')
        verdict = info.get('ì„ ê³ ì¼ì', 'N/A')
        court = info.get('ë²•ì›ëª…', 'N/A')
        summary = info.get('íŒê²°ìš”ì§€', 'N/A').replace('\n',' ')
        body = info.get('íŒë¡€ë‚´ìš©','N/A')[:500].replace('\n',' ')
        ref = info.get('ì°¸ì¡°ì¡°ë¬¸','N/A')
        return f"""
---
**ğŸ” íŒë¡€ ì „ë¬¸ ì „ì²´ (ë²•ì œì²˜ ì‹¤ì‹œê°„ í˜¸ì¶œ)**
**ì‚¬ê±´ëª…**: {title}
**ì„ ê³ **: {verdict} | **ë²•ì›**: {court}
**íŒë¡€ ë§í¬**: [ë²•ì œì²˜ ë°”ë¡œê°€ê¸°](http://www.law.go.kr/precInfo.do?precSeq={prec_id})
**íŒê²°ìš”ì§€**: {summary}
**ì „ë¬¸ ì¼ë¶€ (500ì)**: {body}...
**ì°¸ì¡°ì¡°ë¬¸**: {ref}
---
"""
    except Exception as e:
        return f"---\n[API ë¶„ì„ ì‹¤íŒ¨]: {e}\n---"

# ======================================================
# 4. ê²Œë¦´ë¼ RAG (íƒ„ì•½ê³ )
# ======================================================
EMBED_MODEL = "models/text-embedding-004"

def embed_text(text, task_type="RETRIEVAL_DOCUMENT"):
    try:
        res = genai.embed_content(model=EMBED_MODEL, content=text, task_type=task_type)
        return np.array(res['embedding'], dtype=float)
    except Exception:
        return None

@st.cache_data(show_spinner=False)
def load_and_embed_precedents(file_path):
    try:
        if file_path.startswith("http"):
            r = requests.get(file_path, timeout=10)
            r.raise_for_status()
            content = r.text
        else:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
    except Exception:
        return [], np.array([])

    precedents = [p.strip() for p in content.split('---END OF PRECEDENT---') if p.strip()]
    if not precedents:
        return [], np.array([])

    emb_list, valid = [], []
    for p in precedents:
        emb = embed_text(p)
        if emb is not None:
            emb_list.append(emb)
            valid.append(p)
    return valid, np.vstack(emb_list) if emb_list else np.array([])

def find_similar_precedents(query, precedents, embeddings, top_k=5):
    if embeddings.size == 0:
        return []
    q_emb = embed_text(query, task_type="RETRIEVAL_QUERY")
    if q_emb is None:
        return []
    emb_norms = np.linalg.norm(embeddings, axis=1)
    q_norm = np.linalg.norm(q_emb)
    sims = np.dot(embeddings, q_emb) / (emb_norms * q_norm)
    top_k_idx = np.argsort(sims)[-top_k:][::-1]
    selected_docs = []
    for i in top_k_idx:
        sim = sims[i]
        text = precedents[i]
        selected_docs.append({"similarity": float(sim), "text": text})
    return selected_docs

# ======================================================
# 5. SYSTEM PROMPT
# ======================================================
try:
    with open("system_prompt.txt","r",encoding="utf-8") as f:
        SYSTEM_INSTRUCTION = f.read()
except Exception:
    SYSTEM_INSTRUCTION = "ë‹¹ì‹ ì€ ë²•ë¥  AI ì‹œìŠ¤í…œ 'ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„'ì…ë‹ˆë‹¤."

RAW_URL = "https://raw.githubusercontent.com/deokjune85-rgb/imdmirage/main/precedents_data.txt"

if "precedents" not in st.session_state:
    st.session_state.precedents, st.session_state.embeddings = load_and_embed_precedents(RAW_URL)

if "model" not in st.session_state:
    st.session_state.model = genai.GenerativeModel("gemini-2.5-flash", system_instruction=SYSTEM_INSTRUCTION)

if "chat" not in st.session_state:
    st.session_state.chat = st.session_state.model.start_chat(history=[])
    st.session_state.messages = []
    initial_prompt = "ì‹œìŠ¤í…œ ê°€ë™. 'ë™ì  ë¼ìš°íŒ… í”„ë¡œí† ì½œ'ì„ ì‹¤í–‰í•˜ì—¬ Phase 0ë¥¼ ì‹œì‘í•˜ë¼."
    try:
        response = st.session_state.chat.send_message(initial_prompt)
        st.session_state.messages.append({"role": "Architect", "content": response.text})
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# ======================================================
# 6. UI / CHAT
# ======================================================
for msg in st.session_state.messages:
    role = "Client" if msg["role"] == "user" else "Architect"
    avatar = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ›¡ï¸"
    with st.chat_message(role, avatar=avatar):
        st.markdown(msg["content"])

if prompt := st.chat_input("ì‹œë®¬ë ˆì´ì…˜ ë³€ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹­ì‹œì˜¤."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("Client", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    with st.spinner("Architect ì‹œìŠ¤í…œ ì—°ì‚° ì¤‘..."):
        try:
            response_stream = st.session_state.chat.send_message(prompt, stream=True)
            with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
                placeholder = st.empty()
                answer = ""
                for chunk in response_stream:
                    # === ìë™ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (Phase êµ¬ë¬¸ ì •ë¦¬) ===
                    chunk_text = chunk.text.replace("2-1.", "\n2-1.").replace("2-2.", "\n2-2.").replace("2-3.", "\n2-3.").replace("2-4.", "\n2-4.").replace("2-5.", "\n2-5.").replace("2-6.", "\n2-6.").replace("2-7.", "\n2-7.").replace("2-8.", "\n2-8.")
                    answer += chunk_text
                    placeholder.markdown(f"<div style='white-space:pre-wrap; color:#FFFFFF; font-size:16px; line-height:1.7;'>{answer}â–Œ</div>", unsafe_allow_html=True)
                placeholder.markdown(f"<div style='white-space:pre-wrap; color:#FFFFFF; font-size:16px; line-height:1.7;'>{answer}</div>", unsafe_allow_html=True)

            # ======================================================
            # âœ… Phase-End íŒë¡€ ìë™ í›„ì²˜ë¦¬ (ìµœì¢… ì¶œë ¥ ì‹œ)
            # ======================================================
            if (
                any(kw in answer for kw in ["ìµœì¢…", "ë³´ê³ ì„œ", "ë¸Œë¦¬í•‘", "ê²°ê³¼ ìš”ì•½", "ì™„ë£Œ"])
                and not any(kw in answer for kw in ["ì…ë ¥", "Phase", "ë‹¨ê³„", "ì‹œì‘"])
            ):
                selected_docs = find_similar_precedents(
                    prompt, st.session_state.precedents, st.session_state.embeddings
                )
                if selected_docs:
                    report_md = "### ğŸ§¾ ì‹¤ì‹œê°„ íŒë¡€ ì „ë¬¸ ë¶„ì„ (ìµœì¢…)\n\n"
                    report_md += f"* ê²€ìƒ‰ ì¿¼ë¦¬: `{prompt}`\n\n"
                    for doc in selected_docs:
                        sim = doc["similarity"]
                        text = doc["text"]
                        lines = text.split('\n')
                        title = lines[0][:80] if lines else "ì œëª© ì—†ìŒ"
                        excerpt = " ".join(lines[1:5])[:300].strip()
                        report_md += (
                            f"* íŒë¡€ [{title}](#)\n"
                            f"  - ìœ ì‚¬ë„: {sim*100:.0f}%\n"
                            f"  - ì „ë¬¸ ì¼ë¶€: \"{excerpt}...\"\n\n"
                        )
                    with st.chat_message("Architect", avatar="ğŸ›¡ï¸"):
                        st.markdown(
                            f"<div style='font-family:Noto Sans KR; color:#FFFFFF; font-size:16px; line-height:1.7;'>{report_md}</div>",
                            unsafe_allow_html=True
                        )
                    st.session_state.messages.append({"role": "Architect", "content": report_md})

            st.session_state.messages.append({"role": "Architect", "content": answer})

        except Exception as e:
            st.error(f"ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {e}")
