# -*- coding: utf-8 -*-
# ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1.2 â€” Auto-Analysis Mode + Dual RAG (ì½”ë“œ ë©¸ê·  ë° í™˜ê²½ í˜¸í™˜ì„± ê°•í™”)

import streamlit as st
import google.generativeai as genai
import os
import numpy as np
import re
import time
import json
import PyPDF2 # PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìˆ˜

# ---------------------------------------
# 0. ê¸°ë³¸ ì„¸íŒ…
# ---------------------------------------
st.set_page_config(
    page_title="ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1",
    page_icon="ğŸ›¡ï¸",
    layout="centered"
)

# CSS (ëª¨ë“  ê³µë°±ì€ í‘œì¤€ ê³µë°± U+0020ìœ¼ë¡œ ì •ì œë¨)
custom_css = """
<style>
#MainMenu, footer, header, .stDeployButton {visibility:hidden;}
html, body, div, span, p {
    font-family: 'Noto Sans KR', sans-serif !important;
    font-size: 16px !important;
    line-height: 1.7 !important;
}
h1 {
    text-align: left !important;
    font-weight: 900 !important;
    font-size: 36px !important;
    margin-top: 10px !important;
    margin-bottom: 15px !important;
}
strong, b { font-weight: 700; }
.fadein { animation: fadeInText 0.5s ease-in-out forwards; opacity: 0; }
@keyframes fadeInText {
    from {opacity: 0; transform: translateY(3px);}
    to {opacity: 1; transform: translateY(0);}
}
[data-testid="stChatMessageContent"] {
    font-size: 16px !important;
}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

st.title("ë² ë¦¬íƒ€ìŠ¤ ì—”ì§„ 8.1")
st.caption("The Architect â€” ì „ëµ ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„")

# ì´ëª¨ì§€ ì œê±° ë° í…ìŠ¤íŠ¸ ìˆ˜ì • (í˜¸í™˜ì„± ê°•í™”)
st.warning(
    "ë³´ì•ˆ ê²½ê³ : ë³¸ ì‹œìŠ¤í…œì€ ê²©ë¦¬ëœ ì‚¬ì„¤ í™˜ê²½(The Vault)ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. "
    "ëª¨ë“  ë°ì´í„°ëŠ” ê¸°ë°€ë¡œ ì·¨ê¸‰ë˜ë©° ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
)

# ---------------------------------------
# 1. API í‚¤ ì„¤ì •
# ---------------------------------------
try:
    # Streamlit Cloud ë°°í¬ ì‹œ st.secrets ì‚¬ìš©
    if "GOOGLE_API_KEY" in st.secrets:
        API_KEY = st.secrets["GOOGLE_API_KEY"]
    # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© (ì„ íƒ ì‚¬í•­)
    else:
        API_KEY = os.environ.get("GOOGLE_API_KEY")

    if not API_KEY:
        raise ValueError("API Key not found in secrets or environment variables.")
    genai.configure(api_key=API_KEY)
except (KeyError, ValueError) as e:
    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: ì—”ì§„ ì—°ê²° ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”. {e}")
    st.stop()

# ---------------------------------------
# 2. ì„ë² ë”© / RAG ìœ í‹¸
# ---------------------------------------
EMBEDDING_MODEL_NAME = "models/text-embedding-004"

def embed_text(text: str, task_type: str = "retrieval_document"):
    clean_text = text.replace("\n", " ").strip()
    if not clean_text:
        return None
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL_NAME,
            content=clean_text,
            task_type=task_type,
        )
        return result["embedding"]
    except Exception as e:
        print(f"[Embedding error] {e}")
        return None

# ---------------------------------------
# 2-1. ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”© ë¡œë“œ
# ---------------------------------------
@st.cache_data(show_spinner=False)
def load_precomputed_embeddings():
    """ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”© ë¡œë“œ (0.5ì´ˆ ì™„ë£Œ)"""
    statute_items = []
    statute_embeddings = []
    precedent_items = []
    precedent_embeddings = []
    
    # ë²•ë ¹ ë¡œë“œ
    if os.path.exists("statutes_embeddings.npy") and os.path.exists("statutes_items.json"):
        statute_embeddings = np.load("statutes_embeddings.npy").tolist()
        with open("statutes_items.json", "r", encoding="utf-8") as f:
            statute_items = json.load(f)
        print(f"[RAG] ë²•ë ¹ ë¡œë“œ ì™„ë£Œ: {len(statute_items)}ê°œ")
    
    # íŒë¡€ ë¡œë“œ
    if os.path.exists("precedents_embeddings.npy") and os.path.exists("precedents_items.json"):
        precedent_embeddings = np.load("precedents_embeddings.npy").tolist()
        with open("precedents_items.json", "r", encoding="utf-8") as f:
            precedent_items = json.load(f)
        print(f"[RAG] íŒë¡€ ë¡œë“œ ì™„ë£Œ: {len(precedent_items)}ê°œ")
    
    return statute_items, statute_embeddings, precedent_items, precedent_embeddings

def find_similar_items(query_text, items, embeddings, top_k=3, threshold=0.5):
    if not items or not embeddings:
        return []

    q_emb = embed_text(query_text, task_type="retrieval_query")
    if q_emb is None:
        return []

    # ì•ˆì •ì„±ì„ ìœ„í•´ ë°ì´í„° íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ ë³€í™˜
    try:
        embeddings_np = np.array(embeddings, dtype=np.float32)
        q_emb_np = np.array(q_emb, dtype=np.float32)
    except ValueError as e:
        print(f"[RAG Error] ì„ë² ë”© ë°ì´í„° íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}")
        return []

    # ì„ë² ë”© ì°¨ì› í™•ì¸
    if embeddings_np.size > 0:
        if embeddings_np.shape[1] != len(q_emb_np):
            print(f"[RAG Error] ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: DB={embeddings_np.shape[1]}, Query={len(q_emb_np)}")
            return []
    else:
        return []

    sims = np.dot(embeddings_np, q_emb_np)
    idxs = np.argsort(sims)[::-1][:top_k]

    results = []
    for i in idxs:
        score = float(sims[i])
        if score < threshold:
            continue
        item = items[i].copy()
        item["similarity"] = score
        results.append(item)

    return results

# ---------------------------------------
# 3. PDF ì²˜ë¦¬ í•¨ìˆ˜ (ì§„ë‹¨ ê°•í™”ë¨ v8.1.2)
# ---------------------------------------
def extract_text_from_pdf(uploaded_file):
    """PDF í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , ì‹¤íŒ¨ ì‹œ ì›ì¸ ì½”ë“œë¥¼ ë°˜í™˜í•œë‹¤."""
    try:
        # [ê°œì„  1] ì•ˆì •ì„± í™•ë³´: ìŠ¤íŠ¸ë¦¼ ìœ„ì¹˜ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¼ (Streamlit íŠ¹ì„± ê³ ë ¤)
        uploaded_file.seek(0)
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        
        # [ê°œì„  2] ì•”í˜¸í™” í™•ì¸
        if pdf_reader.is_encrypted:
             return "[ERROR:ENCRYPTED]"

        text = ""
        
        for page_num, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text()
            if page_text:
                # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì˜ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (ê³µë°± ì œê±°)
                cleaned_text = page_text.strip()
                if cleaned_text:
                    # í˜ì´ì§€ ë²ˆí˜¸ í‘œì‹œ (ì´ëª¨ì§€ ì œê±°)
                    text += f"\n--- í˜ì´ì§€ {page_num + 1} ---\n"
                    text += cleaned_text
        
        # [ê°œì„  3] ë‚´ìš©ë¬¼ ì—†ìŒ ê°ì§€ (ìŠ¤ìº” PDF ì§„ë‹¨)
        if not text.strip():
            # ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬ í›„ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ìŠ¤ìº”ëœ PDF ë˜ëŠ” ë¹ˆ íŒŒì¼ë¡œ ê°„ì£¼
            return "[ERROR:NO_TEXT]"

        return text.strip()
    
    except Exception as e:
        # ì²˜ë¦¬ ì‹¤íŒ¨ ê°ì§€ (ì†ìƒ ë“±)
        print(f"[PDF Extraction Error] {e}") # ë””ë²„ê¹…ìš© ì„œë²„ ë¡œê·¸
        return f"[ERROR:PROCESSING_FAILED]"


def analyze_case_file(pdf_text: str):
    """PDF í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•œë‹¤."""
    # í”„ë¡¬í”„íŠ¸ (ì´ëª¨ì§€ ì œê±°)
    analysis_prompt = f"""
ë‹¤ìŒì€ ì‚¬ê±´ê¸°ë¡ PDFì—ì„œ ì¶”ì¶œí•œ ë‚´ìš©ì…ë‹ˆë‹¤.

[PDF ë‚´ìš©]
{pdf_text[:15000]} # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ê³ ë ¤

[ë¶„ì„ ì§€ì¹¨]
1. ì´ ì‚¬ê±´ì˜ ë„ë©”ì¸ ë¶„ë¥˜ (í˜•ì‚¬/ë¯¼ì‚¬/ê°€ì‚¬/í–‰ì •/íŒŒì‚°/IP/ì˜ë£Œ/ì„¸ë¬´ ì¤‘ 1ê°œ)
2. ì„¸ë¶€ ë¶„ì•¼ (ì˜ˆ: í˜•ì‚¬-ë§ˆì•½, ë¯¼ì‚¬-ê³„ì•½ë¶„ìŸ ë“±)
3. í•µì‹¬ ì‚¬ì‹¤ê´€ê³„ 5ê°€ì§€ (ì‹œê°„ìˆœ ë˜ëŠ” ì¤‘ìš”ë„ìˆœ)
4. í™•ë³´ëœ ì¦ê±° ëª©ë¡ (ë¬¸ì„œëª…, ì¢…ë¥˜)
5. í”¼ê³ ì¸/ì›ê³  ì¸¡ ì£¼ì¥ ìš”ì•½
6. ìƒëŒ€ë°© ì¸¡ ì£¼ì¥ ìš”ì•½

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”. (```json ë§ˆí¬ë‹¤ìš´ í¬í•¨)

```json
{{
  "domain": "í˜•ì‚¬",
  "subdomain": "ë§ˆì•½",
  "key_facts": ["ì‚¬ì‹¤ 1", "ì‚¬ì‹¤ 2", "ì‚¬ì‹¤ 3", "ì‚¬ì‹¤ 4", "ì‚¬ì‹¤ 5"],
  "evidence": ["ì¦ê±° 1", "ì¦ê±° 2"],
  "our_claim": "ìš°ë¦¬ ì¸¡ ì£¼ì¥ ìš”ì•½",
  "their_claim": "ìƒëŒ€ë°© ì¸¡ ì£¼ì¥ ìš”ì•½"
}}
