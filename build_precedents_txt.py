import requests
import xml.etree.ElementTree as ET
import time

# ==============================
# ì„¤ì •ê°’
# ==============================
BASE_URL = "https://www.law.go.kr"
OC = "deokjune"  # ë„¤ê°€ ì“°ëŠ” law.go.kr ì•„ì´ë”” ì•ë¶€ë¶„

# ê²°ê³¼ë¥¼ ì €ì¥í•  TXT íŒŒì¼ ê²½ë¡œ
OUTPUT_PATH = "precedents_data.txt"

# ğŸ‘‰ ì—¬ê¸° í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì—ë‹¤ê°€ ì›í•˜ëŠ” ì£„ëª…/í‚¤ì›Œë“œ ê³„ì† ì¶”ê°€í•˜ë©´ ë¨
KEYWORDS = [
    "ìŒì£¼ìš´ì „",
    "ì‚¬ê¸°",
    "ì ˆë„",
    "í­í–‰",
    "ìƒí•´",
    "íŠ¹ìˆ˜ìƒí•´",
    "íŠ¹ê°€ë²•",
    "ì„±í­ë ¥",
    "ì„±ë§¤ë§¤",
    "íš¡ë ¹",
    "ë°°ì„",
    "ë„ë°•",
    "ë§ˆì•½",
    "ìœ ì‚¬ìˆ˜ì‹ ",
    "ê³µê°ˆ",
    "í˜‘ë°•",
    "ê°•ë„",
    "ì‚´ì¸",
]


# ==============================
# íŒë¡€ ëª©ë¡ ê²€ìƒ‰ (lawSearch.do)
# ==============================
def search_prec_ids_by_keyword(keyword: str, max_pages: int = 5, display: int = 20):
    """
    íŠ¹ì • í‚¤ì›Œë“œë¡œ íŒë¡€ ê²€ìƒ‰í•´ì„œ 'íŒë¡€ì¼ë ¨ë²ˆí˜¸' ëª©ë¡ë§Œ ë½‘ì•„ì˜¤ëŠ” í•¨ìˆ˜
    """
    all_ids = []
    for page in range(1, max_pages + 1):
        params = {
            "OC": OC,
            "target": "prec",
            "type": "XML",
            "query": keyword,
            "page": page,
            "display": display,
        }
        url = f"{BASE_URL}/DRF/lawSearch.do"
        resp = requests.get(url, params=params, timeout=10)
        resp.raise_for_status()

        root = ET.fromstring(resp.content)

        # ì „ì²´ ê±´ìˆ˜ (í•„ìš”í•˜ë©´ ì‚¬ìš©)
        total_cnt_text = root.findtext("totalCnt", default="0") or "0"
        try:
            total_cnt = int(total_cnt_text)
        except ValueError:
            total_cnt = 0

        for prec in root.findall("prec"):
            pid = prec.findtext("íŒë¡€ì¼ë ¨ë²ˆí˜¸")
            if pid and pid not in all_ids:
                all_ids.append(pid)

        # ë” ì´ìƒ í˜ì´ì§€ ì—†ìœ¼ë©´ ëŠê¸° (ëŒ€ëµ)
        if page * display >= total_cnt:
            break

        time.sleep(0.2)  # ë„ˆë¬´ ë¹¡ì„¸ê²Œ ì•ˆ ë‘ë“¤ê¸°ê²Œ ì‚´ì§ ë”œë ˆì´

    return all_ids


# ==============================
# íŒë¡€ ìƒì„¸ ì¡°íšŒ (lawService.do)
# ==============================
def fetch_prec_detail(prec_id: str) -> dict:
    """
    lawService.do ë¡œ íŒë¡€ ìƒì„¸ ë‚´ìš© ë°›ì•„ì˜¤ê¸°
    """
    params = {
        "OC": OC,
        "target": "prec",
        "type": "XML",
        "ID": prec_id,
    }
    url = f"{BASE_URL}/DRF/lawService.do"
    resp = requests.get(url, params=params, timeout=10)
    resp.raise_for_status()

    root = ET.fromstring(resp.content)

    def get(tag: str) -> str:
        el = root.find(tag)
        if el is None or el.text is None:
            return ""
        return el.text.strip()

    data = {
        "íŒë¡€ì¼ë ¨ë²ˆí˜¸": prec_id,
        "ì‚¬ê±´ëª…": get("ì‚¬ê±´ëª…"),
        "ì‚¬ê±´ë²ˆí˜¸": get("ì‚¬ê±´ë²ˆí˜¸"),
        "ì„ ê³ ì¼ì": get("ì„ ê³ ì¼ì"),
        "ë²•ì›ëª…": get("ë²•ì›ëª…"),
        "ì‚¬ê±´ì¢…ë¥˜ëª…": get("ì‚¬ê±´ì¢…ë¥˜ëª…"),
        "íŒê²°ìœ í˜•": get("íŒê²°ìœ í˜•"),
        "íŒì‹œì‚¬í•­": get("íŒì‹œì‚¬í•­"),
        "íŒê²°ìš”ì§€": get("íŒê²°ìš”ì§€"),
        "ì°¸ì¡°ì¡°ë¬¸": get("ì°¸ì¡°ì¡°ë¬¸"),
        "ì°¸ì¡°íŒë¡€": get("ì°¸ì¡°íŒë¡€"),
        "íŒë¡€ë‚´ìš©": get("íŒë¡€ë‚´ìš©"),
    }
    return data


# ==============================
# TXTì— ë“¤ì–´ê°ˆ í•œ ê±´ í¬ë§·íŒ…
# ==============================
def make_precedent_block(kw: str, data: dict) -> str:
    """
    RAGì—ì„œ ìª¼ê°¤ ìˆ˜ ìˆê²Œ
    ==== PRECEDENT START ==== / ==== PRECEDENT END ====
    í˜•íƒœë¡œ í•œ ê±´ì”© ë­‰ì³ì„œ ë¬¸ìì—´ ë§Œë“¤ì–´ì¤Œ
    """
    lines = []
    lines.append("==== PRECEDENT START ====")
    lines.append(f"[ê²€ìƒ‰í‚¤ì›Œë“œ] {kw}")
    lines.append(f"[íŒë¡€ì¼ë ¨ë²ˆí˜¸] {data.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', '')}")
    lines.append(f"[ì‚¬ê±´ëª…] {data.get('ì‚¬ê±´ëª…', '')}")
    lines.append(f"[ì‚¬ê±´ë²ˆí˜¸] {data.get('ì‚¬ê±´ë²ˆí˜¸', '')}")
    lines.append(f"[ì„ ê³ ì¼ì] {data.get('ì„ ê³ ì¼ì', '')}")
    lines.append(f"[ë²•ì›ëª…] {data.get('ë²•ì›ëª…', '')}")
    lines.append(f"[ì‚¬ê±´ì¢…ë¥˜ëª…] {data.get('ì‚¬ê±´ì¢…ë¥˜ëª…', '')}")
    lines.append(f"[íŒê²°ìœ í˜•] {data.get('íŒê²°ìœ í˜•', '')}")
    lines.append("")

    # ê¸´ í…ìŠ¤íŠ¸ë“¤
    for field in ("íŒì‹œì‚¬í•­", "íŒê²°ìš”ì§€", "ì°¸ì¡°ì¡°ë¬¸", "ì°¸ì¡°íŒë¡€", "íŒë¡€ë‚´ìš©"):
        value = data.get(field, "")
        if value:
            lines.append(f"[{field}]")
            lines.append(value)
            lines.append("")

    lines.append("==== PRECEDENT END ====")
    return "\n".join(lines)


# ==============================
# ì „ì²´ ì‹¤í–‰: í‚¤ì›Œë“œ ëŒë©´ì„œ TXT ìƒì„±
# ==============================
def build_precedents_txt():
    seen_ids = set()  # ì¤‘ë³µ ë°©ì§€

    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        for kw in KEYWORDS:
            print(f"\n[*] í‚¤ì›Œë“œ '{kw}' íŒë¡€ ìˆ˜ì§‘ ì¤‘...")
            try:
                ids = search_prec_ids_by_keyword(kw, max_pages=5, display=20)
            except Exception as e:
                print(f"[!] í‚¤ì›Œë“œ '{kw}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue

            print(f"    - ê²€ìƒ‰ëœ íŒë¡€ì¼ë ¨ë²ˆí˜¸ ê°œìˆ˜: {len(ids)}")

            for pid in ids:
                if pid in seen_ids:
                    continue
                seen_ids.add(pid)

                try:
                    detail = fetch_prec_detail(pid)
                except Exception as e:
                    print(f"[!] íŒë¡€ {pid} ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    continue

                block = make_precedent_block(kw, detail)
                f.write(block + "\n\n")

                # ë„ˆë¬´ ê³¼ë„í•œ í˜¸ì¶œ ë°©ì§€
                time.sleep(0.2)

    print(f"\nâœ… ì™„ë£Œ: {OUTPUT_PATH} íŒŒì¼ ìƒì„±ë¨")


if __name__ == "__main__":
    build_precedents_txt()
